{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neueral Network Model to predict winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters\n",
    "from functools import partial\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mvp_data.csv\", index_col=0).reset_index(drop=True)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define points+rebounds+assists variable\n",
    "df['PRA'] = df['PTS'] + df['TRB'] + df['AST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variables used for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables used for regression (mutual_info from lin_reg model)\n",
    "cols = ['PRA', 'WS/48', 'player_efficiency_rating', 'offensive_box_plus_minus',\n",
    "       'value_over_replacement_player', 'wl_pct', 'seed']\n",
    "#X = df[cols]\n",
    "#y = df['Share']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop 1982, 1999, 2005, 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_yrs = [1982, 1999, 2005, 2006]\n",
    "mask = ~df['Year'].isin(drop_yrs)\n",
    "df = df[mask]\n",
    "\n",
    "years = list(range(1980,2024))\n",
    "yrs = [y for y in years if y not in drop_yrs]\n",
    "rand_years = random.sample(yrs, 4)\n",
    "test_year = rand_years[0]\n",
    "valid_years = rand_years[1:]\n",
    "\n",
    "df_test = df[df['Year'] == test_year]\n",
    "df_valid = df[df['Year'].isin(valid_years)]\n",
    "df_train = df[~df['Year'].isin(rand_years)]\n",
    "X_test =  df_test[cols]\n",
    "y_test = df_test['Share']\n",
    "X_valid =  df_valid[cols]\n",
    "y_valid = df_valid['Share']\n",
    "X_train = df_train[cols]\n",
    "y_train = df_train['Share']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2019, 1980, 2023, 1990]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE and ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test network with one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## NO BATCH NORMALIZATION or DROPOUT #########\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "initializer = tf.keras.initializers.LecunNormal(seed=42)\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"selu\", kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(50, activation=\"selu\", kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(50, activation=\"selu\", kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(50, activation=\"selu\", kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "#initializer = tf.keras.initializers.LecunNormal(seed=42)\n",
    "RegularizedDense = partial(tf.keras.layers.Dense, \n",
    "                            activation=\"relu\", kernel_initializer='he_normal')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder to store logs of training\n",
    "shutil.rmtree(\"nn_test1\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 13:47:36.592197: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-23 13:47:36.592220: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-01-23 13:47:36.595924: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "# define function to generate path of the log subdirectory based on the current date and time\n",
    "# will allow to view training results via TensorBoard\n",
    "def get_run_logdir(root_logdir=\"nn_test1\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir,\n",
    "                                                profile_batch=(100, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11/11 [==============================] - 2s 27ms/step - loss: 0.0632 - root_mean_squared_error: 0.2514 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0399 - root_mean_squared_error: 0.1996 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1948\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0319 - root_mean_squared_error: 0.1785 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1822\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0252 - root_mean_squared_error: 0.1588 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0246 - root_mean_squared_error: 0.1568 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0248 - root_mean_squared_error: 0.1573 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0245 - root_mean_squared_error: 0.1565 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - root_mean_squared_error: 0.1524 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1852\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0217 - root_mean_squared_error: 0.1472 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0196 - root_mean_squared_error: 0.1399 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 12/15\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.0190 - root_mean_squared_error: 0.1379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 13:49:24.693318: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-23 13:49:24.693341: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0188 - root_mean_squared_error: 0.1370 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1848\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0155 - root_mean_squared_error: 0.1247 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1850\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0165 - root_mean_squared_error: 0.1284 - val_loss: 0.0479 - val_root_mean_squared_error: 0.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 13:49:25.623564: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-01-23 13:49:25.668424: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=15,\n",
    "                    validation_data=(X_valid,y_valid),\n",
    "                    callbacks=[tensorboard_cb]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict and see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7932586104860645\n",
      "MSE: 0.020453000091513872\n"
     ]
    }
   ],
   "source": [
    "print('R2:', r2_score(y_test, pred))\n",
    "print('MSE:', mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Share</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Giannis Antetokounmpo</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.878855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James Harden</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.853921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul George</th>\n",
       "      <td>0.352</td>\n",
       "      <td>0.123961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nikola Jokić</th>\n",
       "      <td>0.210</td>\n",
       "      <td>0.346324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephen Curry</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.188719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Damian Lillard</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.068974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joel Embiid</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.213362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kevin Durant</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.328872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kawhi Leonard</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.041332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russell Westbrook</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.065734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Share  prediction\n",
       "Player                                  \n",
       "Giannis Antetokounmpo  0.932    0.878855\n",
       "James Harden           0.768    0.853921\n",
       "Paul George            0.352    0.123961\n",
       "Nikola Jokić           0.210    0.346324\n",
       "Stephen Curry          0.173    0.188719\n",
       "Damian Lillard         0.068    0.068974\n",
       "Joel Embiid            0.049    0.213362\n",
       "Kevin Durant           0.025    0.328872\n",
       "Kawhi Leonard          0.013    0.041332\n",
       "Russell Westbrook      0.008    0.065734"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test)\n",
    "results['prediction'] = pred\n",
    "results.index = df_test['Player']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 72941), started 4 days, 19:40:56 ago. (Use '!kill 72941' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4b1a0912f532ec04\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4b1a0912f532ec04\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./nn_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impelement early stopping\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"relu_mse1\",\n",
    "                                                         save_best_only=True)\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = Path() / \"relu_mse1\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "#initializer = tf.keras.initializers.LecunNormal(seed=42)\n",
    "RegularizedDense = partial(tf.keras.layers.Dense, \n",
    "                            activation=\"relu\", kernel_initializer='he_normal')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    RegularizedDense(50),\n",
    "    #tf.keras.layers.AlphaDropout(0.1),\n",
    "    tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "11/11 [==============================] - 2s 28ms/step - loss: 0.0565 - root_mean_squared_error: 0.2378 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0405 - root_mean_squared_error: 0.2012 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0332 - root_mean_squared_error: 0.1823 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1753\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0242 - root_mean_squared_error: 0.1557 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
      "Epoch 6/40\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.0244 - root_mean_squared_error: 0.1563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: relu_mse1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: relu_mse1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 154ms/step - loss: 0.0242 - root_mean_squared_error: 0.1554 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1423\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0213 - root_mean_squared_error: 0.1460 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0208 - root_mean_squared_error: 0.1441 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1730\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0202 - root_mean_squared_error: 0.1420 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0489 - val_root_mean_squared_error: 0.2210\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0164 - root_mean_squared_error: 0.1280 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1800\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0165 - root_mean_squared_error: 0.1286 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2191\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0189 - root_mean_squared_error: 0.1376 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1548\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=40,\n",
    "                    validation_data=(X_valid,y_valid),\n",
    "                    callbacks=callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7786135153836946\n",
      "MSE: 0.021901844622225553\n"
     ]
    }
   ],
   "source": [
    "print('R2:', r2_score(y_test, pred))\n",
    "print('MSE:', mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Share</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Giannis Antetokounmpo</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.788757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James Harden</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.679594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul George</th>\n",
       "      <td>0.352</td>\n",
       "      <td>0.085190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nikola Jokić</th>\n",
       "      <td>0.210</td>\n",
       "      <td>0.334042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephen Curry</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.152172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Damian Lillard</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.206050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joel Embiid</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.172204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kevin Durant</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.258893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kawhi Leonard</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.133559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russell Westbrook</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.022105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Share  prediction\n",
       "Player                                  \n",
       "Giannis Antetokounmpo  0.932    0.788757\n",
       "James Harden           0.768    0.679594\n",
       "Paul George            0.352    0.085190\n",
       "Nikola Jokić           0.210    0.334042\n",
       "Stephen Curry          0.173    0.152172\n",
       "Damian Lillard         0.068    0.206050\n",
       "Joel Embiid            0.049    0.172204\n",
       "Kevin Durant           0.025    0.258893\n",
       "Kawhi Leonard          0.013    0.133559\n",
       "Russell Westbrook      0.008    0.022105"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test)\n",
    "results['prediction'] = pred\n",
    "results.index = df_test['Player']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fine-tune hyperparameters\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(norm_layer)\n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer,\n",
    "                  metrics=[\"RootMeanSquaredError\"])\n",
    "    norm_layer.adapt(X_train)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 03s]\n",
      "val_root_mean_squared_error: 0.30875781178474426\n",
      "\n",
      "Best val_root_mean_squared_error So Far: 0.14141060411930084\n",
      "Total elapsed time: 00h 00m 19s\n"
     ]
    }
   ],
   "source": [
    "# create RandomSearch tuner\n",
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=kt.Objective(\"val_root_mean_squared_error\", direction=\"min\"), max_trials=5, overwrite=True,\n",
    "    directory=\"my_mvp\", project_name=\"my_rnd_search\", seed=42)\n",
    "# search for best hps\n",
    "random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 37, 0.007902373711581125, 'sgd']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_hps = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "best_hps = top3_hps[0].values\n",
    "list(best_hps.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n"
     ]
    }
   ],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0151 - root_mean_squared_error: 0.1230\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0137 - root_mean_squared_error: 0.1172\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0136 - root_mean_squared_error: 0.1168\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0124 - root_mean_squared_error: 0.1113\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0126 - root_mean_squared_error: 0.1122\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0111 - root_mean_squared_error: 0.1052\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0121 - root_mean_squared_error: 0.1100\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train, epochs=10)\n",
    "pred = best_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.6828570040562396\n",
      "MSE: 0.031375070760194766\n"
     ]
    }
   ],
   "source": [
    "print('R2:', r2_score(y_test, pred))\n",
    "print('MSE:', mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Share</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Giannis Antetokounmpo</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.922120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James Harden</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.893387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul George</th>\n",
       "      <td>0.352</td>\n",
       "      <td>0.127400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nikola Jokić</th>\n",
       "      <td>0.210</td>\n",
       "      <td>0.298920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephen Curry</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.402054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Damian Lillard</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.034414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joel Embiid</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.365963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kevin Durant</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.305532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kawhi Leonard</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.091919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russell Westbrook</th>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.016355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Share  prediction\n",
       "Player                                  \n",
       "Giannis Antetokounmpo  0.932    0.922120\n",
       "James Harden           0.768    0.893387\n",
       "Paul George            0.352    0.127400\n",
       "Nikola Jokić           0.210    0.298920\n",
       "Stephen Curry          0.173    0.402054\n",
       "Damian Lillard         0.068    0.034414\n",
       "Joel Embiid            0.049    0.365963\n",
       "Kevin Durant           0.025    0.305532\n",
       "Kawhi Leonard          0.013    0.091919\n",
       "Russell Westbrook      0.008   -0.016355"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test)\n",
    "results['prediction'] = pred\n",
    "results.index = df_test['Player']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loop to find best hps for every year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvp_prediction(actual, prediction):\n",
    "    if actual == prediction:\n",
    "        return 'Correct'\n",
    "    else:\n",
    "        return 'Wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, pred):\n",
    "    evals = []\n",
    "    results = pd.DataFrame(y_test)\n",
    "    results['prediction'] = pred\n",
    "    results.index = df_test['Player']\n",
    "    actual = results['Share'].idxmax()\n",
    "    prediction = results['prediction'].idxmax()\n",
    "    evals.append(r2_score(y_test, pred))\n",
    "    evals.append(mean_squared_error(y_test, pred))\n",
    "    evals.append(mvp_prediction(actual, prediction))\n",
    "    return evals, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For loop to hold out every year as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_yrs = [1982, 1999, 2005, 2006]\n",
    "mask = ~df['Year'].isin(drop_yrs)\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 04s]\n",
      "val_root_mean_squared_error: 0.249373197555542\n",
      "\n",
      "Best val_root_mean_squared_error So Far: 0.2215961366891861\n",
      "Total elapsed time: 00h 00m 19s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1508\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0248 - root_mean_squared_error: 0.1575\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0247 - root_mean_squared_error: 0.1571\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0188 - root_mean_squared_error: 0.1370\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0175 - root_mean_squared_error: 0.1321\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0158 - root_mean_squared_error: 0.1258\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0178 - root_mean_squared_error: 0.1334\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0163 - root_mean_squared_error: 0.1276\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0136 - root_mean_squared_error: 0.1168\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0127 - root_mean_squared_error: 0.1127\n",
      "1/1 [==============================] - 0s 125ms/step\n"
     ]
    }
   ],
   "source": [
    "# empty dict to store results\n",
    "evals_by_year = {}\n",
    "\n",
    "best_hps_year={}\n",
    "\n",
    "results_by_year = {}\n",
    "\n",
    "drop_yrs = [1982, 1999, 2005, 2006]\n",
    "years = list(range(1980,2024))\n",
    "yrs = [y for y in years if y not in drop_yrs]\n",
    "\n",
    "for year in yrs:\n",
    "    df_test = df[df['Year'] == year] # create test dataframe of one year\n",
    "    years1 = list(range(1980,2024))\n",
    "    yrs1 = [y for y in years1 if y not in drop_yrs]\n",
    "    yrs1.remove(year) # remove test year from list\n",
    "    valid_years = random.sample(yrs1, 3) # generate 3 random years for validation data\n",
    "    df_valid = df[df['Year'].isin(valid_years)] # create validation dataframe\n",
    "    df_train = df[~df['Year'].isin([year] + list(valid_years))] # training dataframe with remaining years\n",
    "    X_test =  df_test[cols]\n",
    "    y_test = df_test['Share']\n",
    "    X_valid =  df_valid[cols]\n",
    "    y_valid = df_valid['Share']\n",
    "    X_train = df_train[cols]\n",
    "    y_train = df_train['Share']\n",
    "    random_search_tuner = kt.RandomSearch(build_model, objective=kt.Objective(\"val_root_mean_squared_error\", direction=\"min\"), \n",
    "        max_trials=5, overwrite=True, directory=\"my_mvp\", project_name=\"my_rnd_search\", seed=42)\n",
    "    random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))\n",
    "    best_model = random_search_tuner.get_best_models(num_models=1)[0]\n",
    "    #best_model = top2_models[0]\n",
    "    best_model.fit(X_train, y_train, epochs=10)\n",
    "    pred = best_model.predict(X_test)                       \n",
    "    eval, results = evaluate(y_test, pred)\n",
    "    evals_by_year[year] = eval\n",
    "    results_by_year[year] = results\n",
    "    best_hps = random_search_tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "    #best_hps = top3_hps[0].values    \n",
    "    best_hps_year[year] = list(best_hps.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MVP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-0.112554</td>\n",
       "      <td>0.090376</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.590280</td>\n",
       "      <td>0.030378</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.799527</td>\n",
       "      <td>0.019242</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.852155</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.623990</td>\n",
       "      <td>0.037919</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.396298</td>\n",
       "      <td>0.053555</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.573160</td>\n",
       "      <td>0.042863</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.259300</td>\n",
       "      <td>0.067425</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>-0.777560</td>\n",
       "      <td>0.180726</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>0.797727</td>\n",
       "      <td>0.021584</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>-0.611780</td>\n",
       "      <td>0.065130</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.229655</td>\n",
       "      <td>0.039636</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.452022</td>\n",
       "      <td>0.033990</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.695782</td>\n",
       "      <td>0.020666</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.651883</td>\n",
       "      <td>0.027893</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.695890</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.711475</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.444276</td>\n",
       "      <td>0.040603</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.767388</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.731088</td>\n",
       "      <td>0.021714</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.773759</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.874187</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.742851</td>\n",
       "      <td>0.021108</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.776468</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.347696</td>\n",
       "      <td>0.054510</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.579378</td>\n",
       "      <td>0.039304</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.388636</td>\n",
       "      <td>0.059088</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.652461</td>\n",
       "      <td>0.035210</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.717528</td>\n",
       "      <td>0.027095</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.071112</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.772139</td>\n",
       "      <td>0.022211</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.769441</td>\n",
       "      <td>0.023874</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.748054</td>\n",
       "      <td>0.024702</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.519878</td>\n",
       "      <td>0.045558</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.806649</td>\n",
       "      <td>0.019896</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.818512</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.726572</td>\n",
       "      <td>0.027313</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.512342</td>\n",
       "      <td>0.046766</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.820142</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2       MSE      MVP\n",
       "Idx                              \n",
       "1983 -0.112554  0.090376    Wrong\n",
       "1989  0.590280  0.030378    Wrong\n",
       "1993  0.799527  0.019242    Wrong\n",
       "1997  0.852155  0.013961    Wrong\n",
       "1998  0.623990  0.037919    Wrong\n",
       "2001  0.396298  0.053555    Wrong\n",
       "2008  0.573160  0.042863    Wrong\n",
       "2011  0.259300  0.067425    Wrong\n",
       "2017 -0.777560  0.180726    Wrong\n",
       "2023  0.797727  0.021584    Wrong\n",
       "1980 -0.611780  0.065130  Correct\n",
       "1981  0.229655  0.039636  Correct\n",
       "1984  0.452022  0.033990  Correct\n",
       "1985  0.695782  0.020666  Correct\n",
       "1986  0.651883  0.027893  Correct\n",
       "1987  0.695890  0.025616  Correct\n",
       "1988  0.711475  0.025989  Correct\n",
       "1990  0.444276  0.040603  Correct\n",
       "1991  0.767388  0.019265  Correct\n",
       "1992  0.731088  0.021714  Correct\n",
       "1994  0.773759  0.020817  Correct\n",
       "1995  0.874187  0.009444  Correct\n",
       "1996  0.742851  0.021108  Correct\n",
       "2000  0.776468  0.015618  Correct\n",
       "2002  0.269700  0.061481  Correct\n",
       "2003  0.347696  0.054510  Correct\n",
       "2004  0.579378  0.039304  Correct\n",
       "2007  0.388636  0.059088  Correct\n",
       "2009  0.652461  0.035210  Correct\n",
       "2010  0.717528  0.027095  Correct\n",
       "2012  0.229971  0.071112  Correct\n",
       "2013  0.772139  0.022211  Correct\n",
       "2014  0.769441  0.023874  Correct\n",
       "2015  0.748054  0.024702  Correct\n",
       "2016  0.519878  0.045558  Correct\n",
       "2018  0.806649  0.019896  Correct\n",
       "2019  0.818512  0.017955  Correct\n",
       "2020  0.726572  0.027313  Correct\n",
       "2021  0.512342  0.046766  Correct\n",
       "2022  0.820142  0.018221  Correct"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1_res = pd.DataFrame(list(evals_by_year.values()), index=evals_by_year.keys())\n",
    "nn1_res.columns = ['R2', 'MSE', 'MVP']\n",
    "nn1_res.index.name='Idx'\n",
    "#nn1_res.sort_values(by = ['Idx'], ascending = True)\n",
    "nn1_res.sort_values(by = ['MVP', 'Idx'], ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Correct    30\n",
       "Wrong      10\n",
       "Name: MVP, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1_res['MVP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2     0.540409\n",
       "MSE    0.038495\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1_res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1         2     3\n",
       "1980  4  74  0.008611  adam\n",
       "1981  8  37  0.007902   sgd\n",
       "1983  4  74  0.008611  adam\n",
       "1984  4  74  0.008611  adam\n",
       "1985  4  74  0.008611  adam\n",
       "1986  4  74  0.008611  adam\n",
       "1987  8  37  0.007902   sgd\n",
       "1988  4  74  0.008611  adam\n",
       "1989  4  74  0.008611  adam\n",
       "1990  4  74  0.008611  adam\n",
       "1991  8  37  0.007902   sgd\n",
       "1992  4  74  0.008611  adam\n",
       "1993  8  37  0.007902   sgd\n",
       "1994  4  74  0.008611  adam\n",
       "1995  4  74  0.008611  adam\n",
       "1996  4  74  0.008611  adam\n",
       "1997  4  74  0.008611  adam\n",
       "1998  8  37  0.007902   sgd\n",
       "2000  4  74  0.008611  adam\n",
       "2001  8  37  0.007902   sgd\n",
       "2002  4  74  0.008611  adam\n",
       "2003  4  74  0.008611  adam\n",
       "2004  4  74  0.008611  adam\n",
       "2007  4  74  0.008611  adam\n",
       "2008  4  74  0.008611  adam\n",
       "2009  4  74  0.008611  adam\n",
       "2010  8  37  0.007902   sgd\n",
       "2011  8  37  0.007902   sgd\n",
       "2012  4  74  0.008611  adam\n",
       "2013  4  74  0.008611  adam\n",
       "2014  8  37  0.007902   sgd\n",
       "2015  4  74  0.008611  adam\n",
       "2016  8  37  0.007902   sgd\n",
       "2017  4  74  0.008611  adam\n",
       "2018  4  74  0.008611  adam\n",
       "2019  4  74  0.008611  adam\n",
       "2020  4  74  0.008611  adam\n",
       "2021  4  74  0.008611  adam\n",
       "2022  4  74  0.008611  adam\n",
       "2023  4  74  0.008611  adam"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = pd.DataFrame(list(best_hps_year.values()), index=best_hps_year.keys())\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    30\n",
      "8    10\n",
      "Name: 0, dtype: int64\n",
      "74    30\n",
      "37    10\n",
      "Name: 1, dtype: int64\n",
      "0.008611    30\n",
      "0.007902    10\n",
      "Name: 2, dtype: int64\n",
      "adam    30\n",
      "sgd     10\n",
      "Name: 3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in best_hps.columns:\n",
    "    print(best_hps[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use best hyperperameters and relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder to store logs of training\n",
    "shutil.rmtree(\"nn_test2\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_valid, y_valid):\n",
    "    tf.random.set_seed(42)\n",
    "    norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "    model = tf.keras.Sequential([\n",
    "        norm_layer,\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=8e-3)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "    norm_layer.adapt(X_train)\n",
    "    history = model.fit(X_train, y_train, epochs=30,\n",
    "                        validation_data=(X_valid,y_valid),\n",
    "                        callbacks=callbacks\n",
    "                        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 6s 33ms/step - loss: 0.1048 - root_mean_squared_error: 0.3238 - val_loss: 0.0528 - val_root_mean_squared_error: 0.2298\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0414 - root_mean_squared_error: 0.2034 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1993\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0323 - root_mean_squared_error: 0.1798 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1978\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0319 - root_mean_squared_error: 0.1786 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2160\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0314 - root_mean_squared_error: 0.1773 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1846\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0250 - root_mean_squared_error: 0.1580 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0242 - root_mean_squared_error: 0.1554 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0221 - root_mean_squared_error: 0.1485 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1950\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0367 - val_root_mean_squared_error: 0.1916\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0192 - root_mean_squared_error: 0.1387 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1848\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1950\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1905\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 3s 41ms/step - loss: 0.1165 - root_mean_squared_error: 0.3413 - val_loss: 0.0775 - val_root_mean_squared_error: 0.2785\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0448 - root_mean_squared_error: 0.2116 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2240\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0348 - root_mean_squared_error: 0.1866 - val_loss: 0.0518 - val_root_mean_squared_error: 0.2276\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0292 - root_mean_squared_error: 0.1708 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2215\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0245 - root_mean_squared_error: 0.1564 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0220 - root_mean_squared_error: 0.1483 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2143\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2101\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0189 - root_mean_squared_error: 0.1373 - val_loss: 0.0479 - val_root_mean_squared_error: 0.2188\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0189 - root_mean_squared_error: 0.1376 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0197 - root_mean_squared_error: 0.1404 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2149\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0153 - root_mean_squared_error: 0.1238 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2184\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0144 - root_mean_squared_error: 0.1200 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2338\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - val_loss: 0.0655 - val_root_mean_squared_error: 0.2559\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2138\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.0524 - root_mean_squared_error: 0.2290 - val_loss: 0.0623 - val_root_mean_squared_error: 0.2496\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0442 - root_mean_squared_error: 0.2103 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2122\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2076\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0297 - root_mean_squared_error: 0.1723 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1874\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0260 - root_mean_squared_error: 0.1612 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0256 - root_mean_squared_error: 0.1600 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1710\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - root_mean_squared_error: 0.1527 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1717\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1624\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0210 - root_mean_squared_error: 0.1450 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1581\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0181 - root_mean_squared_error: 0.1347 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1827\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0189 - root_mean_squared_error: 0.1376 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0167 - root_mean_squared_error: 0.1291 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1645\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0160 - root_mean_squared_error: 0.1264 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1748\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0128 - root_mean_squared_error: 0.1132 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1695\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0126 - root_mean_squared_error: 0.1121 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - root_mean_squared_error: 0.1097 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0138 - root_mean_squared_error: 0.1176 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 4s 126ms/step - loss: 0.1259 - root_mean_squared_error: 0.3549 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2041\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1996\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0304 - root_mean_squared_error: 0.1742 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1947\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0260 - root_mean_squared_error: 0.1612 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1891\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0235 - root_mean_squared_error: 0.1533 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0237 - root_mean_squared_error: 0.1540 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0207 - root_mean_squared_error: 0.1439 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1717\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1819\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1793\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1700\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0175 - root_mean_squared_error: 0.1323 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1792\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0158 - root_mean_squared_error: 0.1255 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0149 - root_mean_squared_error: 0.1219 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1798\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0136 - root_mean_squared_error: 0.1168 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.0134 - root_mean_squared_error: 0.1156 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0114 - root_mean_squared_error: 0.1069 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 6s 95ms/step - loss: 0.0570 - root_mean_squared_error: 0.2388 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2214\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0338 - root_mean_squared_error: 0.1840 - val_loss: 0.0456 - val_root_mean_squared_error: 0.2135\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0301 - root_mean_squared_error: 0.1735 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2099\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0273 - root_mean_squared_error: 0.1651 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2147\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0209 - root_mean_squared_error: 0.1446 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0197 - root_mean_squared_error: 0.1404 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2121\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2073\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0162 - root_mean_squared_error: 0.1272 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2063\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0149 - root_mean_squared_error: 0.1221 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2147\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0138 - root_mean_squared_error: 0.1174 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0113 - root_mean_squared_error: 0.1065 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2185\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0107 - root_mean_squared_error: 0.1033 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2154\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0102 - root_mean_squared_error: 0.1008 - val_loss: 0.0413 - val_root_mean_squared_error: 0.2031\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0108 - root_mean_squared_error: 0.1041 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2327\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2223\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0102 - root_mean_squared_error: 0.1011 - val_loss: 0.0501 - val_root_mean_squared_error: 0.2237\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2236\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0094 - root_mean_squared_error: 0.0971 - val_loss: 0.0573 - val_root_mean_squared_error: 0.2393\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0084 - root_mean_squared_error: 0.0918 - val_loss: 0.0476 - val_root_mean_squared_error: 0.2182\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 4s 50ms/step - loss: 0.0740 - root_mean_squared_error: 0.2720 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0337 - root_mean_squared_error: 0.1837 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1521\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0283 - root_mean_squared_error: 0.1682 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0245 - root_mean_squared_error: 0.1567 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0256 - root_mean_squared_error: 0.1600 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0258 - root_mean_squared_error: 0.1607 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0238 - root_mean_squared_error: 0.1544 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0215 - root_mean_squared_error: 0.1465 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0202 - root_mean_squared_error: 0.1422 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - root_mean_squared_error: 0.1526 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1472\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0137 - root_mean_squared_error: 0.1169 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1712\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.1570 - root_mean_squared_error: 0.3962 - val_loss: 0.0367 - val_root_mean_squared_error: 0.1917\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0404 - root_mean_squared_error: 0.2010 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2172\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0342 - root_mean_squared_error: 0.1850 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1969\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0324 - root_mean_squared_error: 0.1799 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1871\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0291 - root_mean_squared_error: 0.1706 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1984\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0231 - root_mean_squared_error: 0.1520 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1792\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1908\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1855\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1812\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0413 - val_root_mean_squared_error: 0.2032\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0169 - root_mean_squared_error: 0.1302 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0164 - root_mean_squared_error: 0.1279 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0144 - root_mean_squared_error: 0.1201 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1919\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.0572 - root_mean_squared_error: 0.2392 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1928\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1993\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0334 - root_mean_squared_error: 0.1828 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1856\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0278 - root_mean_squared_error: 0.1666 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2002\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0225 - root_mean_squared_error: 0.1499 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1905\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0221 - root_mean_squared_error: 0.1488 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2013\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0190 - root_mean_squared_error: 0.1377 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1954\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0151 - root_mean_squared_error: 0.1229 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1920\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0144 - root_mean_squared_error: 0.1200 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 40ms/step - loss: 0.1493 - root_mean_squared_error: 0.3864 - val_loss: 0.1108 - val_root_mean_squared_error: 0.3329\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0547 - root_mean_squared_error: 0.2339 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2386\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0403 - root_mean_squared_error: 0.2007 - val_loss: 0.0534 - val_root_mean_squared_error: 0.2310\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2088\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0277 - root_mean_squared_error: 0.1666 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0258 - root_mean_squared_error: 0.1607 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1872\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - root_mean_squared_error: 0.1526 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0238 - root_mean_squared_error: 0.1543 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1975\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1976\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0195 - root_mean_squared_error: 0.1398 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1871\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0187 - root_mean_squared_error: 0.1368 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1869\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0174 - root_mean_squared_error: 0.1319 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1848\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0155 - root_mean_squared_error: 0.1246 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2019\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 41ms/step - loss: 0.0652 - root_mean_squared_error: 0.2553 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1826\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0354 - root_mean_squared_error: 0.1882 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1727\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0310 - root_mean_squared_error: 0.1760 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1930\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0301 - root_mean_squared_error: 0.1734 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2023\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0269 - root_mean_squared_error: 0.1641 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0259 - root_mean_squared_error: 0.1610 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0240 - root_mean_squared_error: 0.1551 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - root_mean_squared_error: 0.1524 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1891\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0206 - root_mean_squared_error: 0.1436 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0199 - root_mean_squared_error: 0.1409 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1619\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1652\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0159 - root_mean_squared_error: 0.1260 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1723\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0136 - root_mean_squared_error: 0.1165 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1753\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0145 - root_mean_squared_error: 0.1203 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0146 - root_mean_squared_error: 0.1206 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1850\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0128 - root_mean_squared_error: 0.1130 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1856\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0109 - root_mean_squared_error: 0.1042 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 32ms/step - loss: 0.0666 - root_mean_squared_error: 0.2580 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0348 - root_mean_squared_error: 0.1866 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1881\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0322 - root_mean_squared_error: 0.1793 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1586\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0258 - root_mean_squared_error: 0.1605 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0261 - root_mean_squared_error: 0.1614 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1660\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0210 - root_mean_squared_error: 0.1450 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0204 - root_mean_squared_error: 0.1429 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1589\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0181 - root_mean_squared_error: 0.1347 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0175 - root_mean_squared_error: 0.1322 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0175 - root_mean_squared_error: 0.1323 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1848\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 4s 36ms/step - loss: 0.0834 - root_mean_squared_error: 0.2887 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0453 - root_mean_squared_error: 0.2128 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2005\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0310 - root_mean_squared_error: 0.1761 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0271 - root_mean_squared_error: 0.1648 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0244 - root_mean_squared_error: 0.1561 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1901\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0244 - root_mean_squared_error: 0.1561 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1873\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0245 - root_mean_squared_error: 0.1566 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2016\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1956\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0178 - root_mean_squared_error: 0.1332 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2141\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2226\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0167 - root_mean_squared_error: 0.1293 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2100\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.0680 - root_mean_squared_error: 0.2608 - val_loss: 0.0471 - val_root_mean_squared_error: 0.2169\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0275 - root_mean_squared_error: 0.1659 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0285 - root_mean_squared_error: 0.1688 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0264 - root_mean_squared_error: 0.1623 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0217 - root_mean_squared_error: 0.1472 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1624\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0202 - root_mean_squared_error: 0.1423 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1624\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 31ms/step - loss: 0.1204 - root_mean_squared_error: 0.3470 - val_loss: 0.0534 - val_root_mean_squared_error: 0.2311\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0369 - root_mean_squared_error: 0.1921 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2111\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0300 - root_mean_squared_error: 0.1732 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2120\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0301 - root_mean_squared_error: 0.1734 - val_loss: 0.0493 - val_root_mean_squared_error: 0.2220\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0260 - root_mean_squared_error: 0.1611 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2104\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0236 - root_mean_squared_error: 0.1537 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2106\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0217 - root_mean_squared_error: 0.1471 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2057\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0196 - root_mean_squared_error: 0.1402 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0193 - root_mean_squared_error: 0.1390 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2059\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0168 - root_mean_squared_error: 0.1297 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2118\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0175 - root_mean_squared_error: 0.1323 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2241\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2185\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0262 - root_mean_squared_error: 0.1620 - val_loss: 0.0495 - val_root_mean_squared_error: 0.2224\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0205 - root_mean_squared_error: 0.1433 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2160\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 40ms/step - loss: 0.1548 - root_mean_squared_error: 0.3935 - val_loss: 0.1048 - val_root_mean_squared_error: 0.3238\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0424 - root_mean_squared_error: 0.2059 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2106\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0358 - root_mean_squared_error: 0.1892 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1768\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0306 - root_mean_squared_error: 0.1749 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1617\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0271 - root_mean_squared_error: 0.1646 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1778\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0252 - root_mean_squared_error: 0.1586 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1812\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0251 - root_mean_squared_error: 0.1584 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1768\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0244 - root_mean_squared_error: 0.1562 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0229 - root_mean_squared_error: 0.1512 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1575\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0205 - root_mean_squared_error: 0.1432 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1710\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0189 - root_mean_squared_error: 0.1373 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1473\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0161 - root_mean_squared_error: 0.1270 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0155 - root_mean_squared_error: 0.1247 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1520\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0163 - root_mean_squared_error: 0.1275 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0167 - root_mean_squared_error: 0.1294 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0148 - root_mean_squared_error: 0.1216 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1602\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0153 - root_mean_squared_error: 0.1239 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1652\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 40ms/step - loss: 0.0851 - root_mean_squared_error: 0.2917 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2227\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2051\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0311 - root_mean_squared_error: 0.1764 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2059\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0240 - root_mean_squared_error: 0.1548 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2155\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0217 - root_mean_squared_error: 0.1473 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2146\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0188 - root_mean_squared_error: 0.1372 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0177 - root_mean_squared_error: 0.1330 - val_loss: 0.0525 - val_root_mean_squared_error: 0.2291\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.0648 - root_mean_squared_error: 0.2546 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0298 - root_mean_squared_error: 0.1727 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1872\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1884\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0262 - root_mean_squared_error: 0.1620 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0218 - root_mean_squared_error: 0.1476 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0200 - root_mean_squared_error: 0.1413 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0201 - root_mean_squared_error: 0.1416 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1909\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0231 - root_mean_squared_error: 0.1521 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1660\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0222 - root_mean_squared_error: 0.1492 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0181 - root_mean_squared_error: 0.1344 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1472\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0139 - root_mean_squared_error: 0.1178 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1795\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0148 - root_mean_squared_error: 0.1216 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1884\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0151 - root_mean_squared_error: 0.1228 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1656\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0102 - root_mean_squared_error: 0.1012 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - root_mean_squared_error: 0.1014 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1959\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 39ms/step - loss: 0.0719 - root_mean_squared_error: 0.2682 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1664\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0299 - root_mean_squared_error: 0.1729 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1872\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0304 - root_mean_squared_error: 0.1745 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1614\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0273 - root_mean_squared_error: 0.1653 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1722\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0229 - root_mean_squared_error: 0.1515 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1854\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1617\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0194 - root_mean_squared_error: 0.1391 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1672\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0167 - root_mean_squared_error: 0.1291 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0143 - root_mean_squared_error: 0.1196 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1873\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0142 - root_mean_squared_error: 0.1192 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1865\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.1641 - root_mean_squared_error: 0.4051 - val_loss: 0.1452 - val_root_mean_squared_error: 0.3810\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0871 - root_mean_squared_error: 0.2952 - val_loss: 0.0857 - val_root_mean_squared_error: 0.2927\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0486 - root_mean_squared_error: 0.2203 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2630\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0409 - root_mean_squared_error: 0.2023 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1953\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0297 - root_mean_squared_error: 0.1722 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2019\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0259 - root_mean_squared_error: 0.1610 - val_loss: 0.0453 - val_root_mean_squared_error: 0.2129\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0243 - root_mean_squared_error: 0.1558 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2014\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - root_mean_squared_error: 0.1525 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2113\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0192 - root_mean_squared_error: 0.1385 - val_loss: 0.0399 - val_root_mean_squared_error: 0.1998\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0181 - root_mean_squared_error: 0.1345 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.0524 - root_mean_squared_error: 0.2289 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1978\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0460 - root_mean_squared_error: 0.2144 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2013\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0550 - val_root_mean_squared_error: 0.2346\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0342 - root_mean_squared_error: 0.1849 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0254 - root_mean_squared_error: 0.1593 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0237 - root_mean_squared_error: 0.1539 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1850\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - root_mean_squared_error: 0.1523 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1712\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1784\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1822\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.1168 - root_mean_squared_error: 0.3417 - val_loss: 0.0503 - val_root_mean_squared_error: 0.2243\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0381 - root_mean_squared_error: 0.1951 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1887\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0317 - root_mean_squared_error: 0.1781 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0295 - root_mean_squared_error: 0.1718 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0236 - root_mean_squared_error: 0.1536 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1875\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0205 - root_mean_squared_error: 0.1431 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0188 - root_mean_squared_error: 0.1372 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1913\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0182 - root_mean_squared_error: 0.1350 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1868\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0168 - root_mean_squared_error: 0.1297 - val_loss: 0.0413 - val_root_mean_squared_error: 0.2033\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 39ms/step - loss: 0.0923 - root_mean_squared_error: 0.3039 - val_loss: 0.0562 - val_root_mean_squared_error: 0.2371\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0324 - root_mean_squared_error: 0.1801 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0308 - root_mean_squared_error: 0.1754 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1990\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0265 - root_mean_squared_error: 0.1627 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1829\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0233 - root_mean_squared_error: 0.1526 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2001\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0202 - root_mean_squared_error: 0.1420 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1752\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0178 - root_mean_squared_error: 0.1336 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1809\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0163 - root_mean_squared_error: 0.1275 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1755\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0136 - root_mean_squared_error: 0.1165 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1847\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0123 - root_mean_squared_error: 0.1107 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1782\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1933\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.0877 - root_mean_squared_error: 0.2961 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2187\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0468 - root_mean_squared_error: 0.2164 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1920\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0434 - root_mean_squared_error: 0.2084 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0309 - root_mean_squared_error: 0.1757 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1871\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0271 - root_mean_squared_error: 0.1646 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1905\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0214 - root_mean_squared_error: 0.1461 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1803\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0198 - root_mean_squared_error: 0.1408 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1794\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0189 - root_mean_squared_error: 0.1374 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0164 - root_mean_squared_error: 0.1280 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0156 - root_mean_squared_error: 0.1251 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0149 - root_mean_squared_error: 0.1220 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 32ms/step - loss: 0.0938 - root_mean_squared_error: 0.3063 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2079\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0348 - root_mean_squared_error: 0.1867 - val_loss: 0.0444 - val_root_mean_squared_error: 0.2106\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0308 - root_mean_squared_error: 0.1754 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0268 - root_mean_squared_error: 0.1637 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1920\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0252 - root_mean_squared_error: 0.1589 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1922\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - root_mean_squared_error: 0.1523 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0199 - root_mean_squared_error: 0.1409 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1852\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0178 - root_mean_squared_error: 0.1336 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1863\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0162 - root_mean_squared_error: 0.1273 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0177 - root_mean_squared_error: 0.1329 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1933\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0187 - root_mean_squared_error: 0.1368 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1886\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1837\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2067\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0136 - root_mean_squared_error: 0.1167 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1966\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0123 - root_mean_squared_error: 0.1108 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0104 - root_mean_squared_error: 0.1020 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2119\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0561 - val_root_mean_squared_error: 0.2369\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0160 - root_mean_squared_error: 0.1267 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1870\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0114 - root_mean_squared_error: 0.1066 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2203\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.1294 - root_mean_squared_error: 0.3598 - val_loss: 0.1118 - val_root_mean_squared_error: 0.3344\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0580 - root_mean_squared_error: 0.2408 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0379 - root_mean_squared_error: 0.1948 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0272 - root_mean_squared_error: 0.1651 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0264 - root_mean_squared_error: 0.1626 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1630\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0259 - root_mean_squared_error: 0.1610 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1647\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0208 - root_mean_squared_error: 0.1444 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1875\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1797\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.0810 - root_mean_squared_error: 0.2847 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0477 - root_mean_squared_error: 0.2185 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1631\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0284 - root_mean_squared_error: 0.1687 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0256 - root_mean_squared_error: 0.1599 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0246 - root_mean_squared_error: 0.1570 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0242 - root_mean_squared_error: 0.1557 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1492\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0190 - root_mean_squared_error: 0.1378 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 63ms/step - loss: 0.0671 - root_mean_squared_error: 0.2591 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1899\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0326 - root_mean_squared_error: 0.1805 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1982\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0321 - root_mean_squared_error: 0.1791 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1772\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0282 - root_mean_squared_error: 0.1681 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0252 - root_mean_squared_error: 0.1586 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2134\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0264 - root_mean_squared_error: 0.1626 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0225 - root_mean_squared_error: 0.1499 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0199 - root_mean_squared_error: 0.1412 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2025\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0169 - root_mean_squared_error: 0.1302 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0231 - root_mean_squared_error: 0.1520 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1973\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.0614 - root_mean_squared_error: 0.2477 - val_loss: 0.0413 - val_root_mean_squared_error: 0.2032\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0427 - root_mean_squared_error: 0.2067 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0301 - root_mean_squared_error: 0.1736 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1634\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0295 - root_mean_squared_error: 0.1717 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1952\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0241 - root_mean_squared_error: 0.1551 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0217 - root_mean_squared_error: 0.1472 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0203 - root_mean_squared_error: 0.1425 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1730\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0208 - root_mean_squared_error: 0.1442 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0196 - root_mean_squared_error: 0.1399 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 3s 34ms/step - loss: 0.0554 - root_mean_squared_error: 0.2354 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2235\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0299 - root_mean_squared_error: 0.1730 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0292 - root_mean_squared_error: 0.1708 - val_loss: 0.0501 - val_root_mean_squared_error: 0.2238\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0273 - root_mean_squared_error: 0.1653 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2113\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0229 - root_mean_squared_error: 0.1513 - val_loss: 0.0481 - val_root_mean_squared_error: 0.2194\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0206 - root_mean_squared_error: 0.1434 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2150\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0193 - root_mean_squared_error: 0.1388 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2065\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0176 - root_mean_squared_error: 0.1326 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0170 - root_mean_squared_error: 0.1302 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2095\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0162 - root_mean_squared_error: 0.1272 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2147\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0162 - root_mean_squared_error: 0.1273 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2104\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0139 - root_mean_squared_error: 0.1178 - val_loss: 0.0489 - val_root_mean_squared_error: 0.2211\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0128 - root_mean_squared_error: 0.1134 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2203\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 38ms/step - loss: 0.0736 - root_mean_squared_error: 0.2713 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0529 - root_mean_squared_error: 0.2299 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0527 - root_mean_squared_error: 0.2297 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0318 - root_mean_squared_error: 0.1782 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0272 - root_mean_squared_error: 0.1648 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0240 - root_mean_squared_error: 0.1550 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0223 - root_mean_squared_error: 0.1495 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1289\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0192 - root_mean_squared_error: 0.1385 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1336\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0171 - root_mean_squared_error: 0.1309 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.1072 - root_mean_squared_error: 0.3274 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0359 - root_mean_squared_error: 0.1894 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0324 - root_mean_squared_error: 0.1800 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1605\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0304 - root_mean_squared_error: 0.1745 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1586\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0261 - root_mean_squared_error: 0.1615 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1524\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1731\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0205 - root_mean_squared_error: 0.1433 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1576\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0179 - root_mean_squared_error: 0.1337 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0160 - root_mean_squared_error: 0.1263 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1695\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - root_mean_squared_error: 0.1183 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1770\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0176 - root_mean_squared_error: 0.1326 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2022\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 52ms/step - loss: 0.0974 - root_mean_squared_error: 0.3121 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2430\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0373 - root_mean_squared_error: 0.1933 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1785\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0519 - val_root_mean_squared_error: 0.2279\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0241 - root_mean_squared_error: 0.1552 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2122\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0221 - root_mean_squared_error: 0.1486 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2413\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0229 - root_mean_squared_error: 0.1515 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2234\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 47ms/step - loss: 0.0200 - root_mean_squared_error: 0.1415 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2127\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0192 - root_mean_squared_error: 0.1387 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2018\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0212 - root_mean_squared_error: 0.1454 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 3s 54ms/step - loss: 0.0699 - root_mean_squared_error: 0.2644 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2378\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0472 - root_mean_squared_error: 0.2173 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2115\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0292 - root_mean_squared_error: 0.1709 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2002\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0270 - root_mean_squared_error: 0.1643 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1861\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0230 - root_mean_squared_error: 0.1515 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1912\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0215 - root_mean_squared_error: 0.1466 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2075\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0213 - root_mean_squared_error: 0.1458 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0192 - root_mean_squared_error: 0.1387 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2230\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0208 - root_mean_squared_error: 0.1441 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2075\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0170 - root_mean_squared_error: 0.1302 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2102\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 32ms/step - loss: 0.0628 - root_mean_squared_error: 0.2506 - val_loss: 0.0386 - val_root_mean_squared_error: 0.1966\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1943\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0310 - root_mean_squared_error: 0.1760 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1615\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0233 - root_mean_squared_error: 0.1526 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1514\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0208 - root_mean_squared_error: 0.1443 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1811\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0195 - root_mean_squared_error: 0.1398 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1460\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0175 - root_mean_squared_error: 0.1324 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1688\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1881\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0186 - root_mean_squared_error: 0.1364 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1795\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0147 - root_mean_squared_error: 0.1211 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0133 - root_mean_squared_error: 0.1153 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1647\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 0.0677 - root_mean_squared_error: 0.2601 - val_loss: 0.0523 - val_root_mean_squared_error: 0.2287\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2289\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0321 - root_mean_squared_error: 0.1793 - val_loss: 0.0539 - val_root_mean_squared_error: 0.2322\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0273 - root_mean_squared_error: 0.1652 - val_loss: 0.0536 - val_root_mean_squared_error: 0.2315\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2252\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0198 - root_mean_squared_error: 0.1407 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2251\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0181 - root_mean_squared_error: 0.1345 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2339\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0186 - root_mean_squared_error: 0.1362 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0159 - root_mean_squared_error: 0.1262 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2143\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0140 - root_mean_squared_error: 0.1184 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2281\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0131 - root_mean_squared_error: 0.1143 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2202\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0147 - root_mean_squared_error: 0.1214 - val_loss: 0.0527 - val_root_mean_squared_error: 0.2295\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0144 - root_mean_squared_error: 0.1198 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2223\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0134 - root_mean_squared_error: 0.1159 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2162\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0108 - root_mean_squared_error: 0.1039 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2289\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0105 - root_mean_squared_error: 0.1026 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2249\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.0549 - root_mean_squared_error: 0.2342 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1858\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0330 - root_mean_squared_error: 0.1816 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1860\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0304 - root_mean_squared_error: 0.1744 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1763\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1639\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1673\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0249 - root_mean_squared_error: 0.1577 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1600\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0178 - root_mean_squared_error: 0.1334 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0182 - root_mean_squared_error: 0.1348 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0162 - root_mean_squared_error: 0.1273 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1427\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0137 - root_mean_squared_error: 0.1169 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1722\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0131 - root_mean_squared_error: 0.1145 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - root_mean_squared_error: 0.1153 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0137 - root_mean_squared_error: 0.1171 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0168 - root_mean_squared_error: 0.1297 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 31ms/step - loss: 0.0506 - root_mean_squared_error: 0.2249 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2330\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0330 - root_mean_squared_error: 0.1817 - val_loss: 0.0837 - val_root_mean_squared_error: 0.2894\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0311 - root_mean_squared_error: 0.1763 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2222\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0285 - root_mean_squared_error: 0.1688 - val_loss: 0.0642 - val_root_mean_squared_error: 0.2534\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0237 - root_mean_squared_error: 0.1540 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2226\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0207 - root_mean_squared_error: 0.1439 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2328\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0192 - root_mean_squared_error: 0.1385 - val_loss: 0.0715 - val_root_mean_squared_error: 0.2674\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0204 - root_mean_squared_error: 0.1430 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2578\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0631 - val_root_mean_squared_error: 0.2512\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0163 - root_mean_squared_error: 0.1276 - val_loss: 0.0475 - val_root_mean_squared_error: 0.2180\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0156 - root_mean_squared_error: 0.1250 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2173\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0147 - root_mean_squared_error: 0.1213 - val_loss: 0.0782 - val_root_mean_squared_error: 0.2796\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0141 - root_mean_squared_error: 0.1186 - val_loss: 0.0501 - val_root_mean_squared_error: 0.2239\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0161 - root_mean_squared_error: 0.1269 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0602 - val_root_mean_squared_error: 0.2453\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0129 - root_mean_squared_error: 0.1134 - val_loss: 0.0686 - val_root_mean_squared_error: 0.2619\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0116 - root_mean_squared_error: 0.1075 - val_loss: 0.0766 - val_root_mean_squared_error: 0.2768\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - val_loss: 0.0749 - val_root_mean_squared_error: 0.2737\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 31ms/step - loss: 0.0630 - root_mean_squared_error: 0.2510 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2056\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0356 - root_mean_squared_error: 0.1886 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2037\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0343 - root_mean_squared_error: 0.1852 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1797\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0274 - root_mean_squared_error: 0.1655 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1859\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0244 - root_mean_squared_error: 0.1562 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1789\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0241 - root_mean_squared_error: 0.1552 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1789\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0222 - root_mean_squared_error: 0.1490 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1721\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0205 - root_mean_squared_error: 0.1430 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0188 - root_mean_squared_error: 0.1373 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1996\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1751\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0148 - root_mean_squared_error: 0.1218 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1884\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0161 - root_mean_squared_error: 0.1268 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1833\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1932\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0161 - root_mean_squared_error: 0.1270 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2053\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0142 - root_mean_squared_error: 0.1193 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2038\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0129 - root_mean_squared_error: 0.1134 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2018\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0134 - root_mean_squared_error: 0.1157 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 38ms/step - loss: 0.0723 - root_mean_squared_error: 0.2689 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1875\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0471 - root_mean_squared_error: 0.2170 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0367 - root_mean_squared_error: 0.1916 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1880\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0281 - root_mean_squared_error: 0.1677 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1735\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1913\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0315 - root_mean_squared_error: 0.1776 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - root_mean_squared_error: 0.1525 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1883\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0214 - root_mean_squared_error: 0.1461 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1608\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0199 - root_mean_squared_error: 0.1409 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 30ms/step - loss: 0.0631 - root_mean_squared_error: 0.2512 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2113\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0393 - root_mean_squared_error: 0.1984 - val_loss: 0.0471 - val_root_mean_squared_error: 0.2171\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0310 - root_mean_squared_error: 0.1762 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1858\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0273 - root_mean_squared_error: 0.1652 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0262 - root_mean_squared_error: 0.1620 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0239 - root_mean_squared_error: 0.1547 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1967\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0197 - root_mean_squared_error: 0.1405 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2046\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0184 - root_mean_squared_error: 0.1357 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2013\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2073\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0163 - root_mean_squared_error: 0.1278 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2109\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0146 - root_mean_squared_error: 0.1208 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094\n"
     ]
    }
   ],
   "source": [
    "# empty dict to store results\n",
    "evals_by_year = {}\n",
    "\n",
    "results_by_year={}\n",
    "\n",
    "drop_yrs = [1982, 1999, 2005, 2006]\n",
    "years = list(range(1980,2024))\n",
    "yrs = [y for y in years if y not in drop_yrs]\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "for year in yrs:\n",
    "    df_test = df[df['Year'] == year] # create test dataframe of one year\n",
    "    years1 = list(range(1980,2024))\n",
    "    yrs1 = [y for y in years1 if y not in drop_yrs]\n",
    "    yrs1.remove(year) # remove test year from list\n",
    "    valid_years = random.sample(yrs1, 4) # generate 4 random years for validation data\n",
    "    df_valid = df[df['Year'].isin(valid_years)] # create validation dataframe\n",
    "    df_train = df[~df['Year'].isin([year] + list(valid_years))] # training dataframe with remaining years\n",
    "    X_test =  df_test[cols]\n",
    "    y_test = df_test['Share']\n",
    "    X_valid =  df_valid[cols]\n",
    "    y_valid = df_valid['Share']\n",
    "    X_train = df_train[cols]\n",
    "    y_train = df_train['Share']\n",
    "    tf.random.set_seed(42)\n",
    "    norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "    model = tf.keras.Sequential([\n",
    "        norm_layer,\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=8e-3)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "    norm_layer.adapt(X_train)\n",
    "    history = model.fit(X_train, y_train, epochs=30,\n",
    "                        validation_data=(X_valid,y_valid),\n",
    "                        callbacks=callbacks\n",
    "                        )\n",
    "    pred = model(X_test)                       \n",
    "    eval, results = evaluate(y_test, pred)\n",
    "    evals_by_year[year] = eval\n",
    "    results_by_year[year] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with train function\n",
    "# empty dict to store results\n",
    "evals_by_year = {}\n",
    "\n",
    "results_by_year={}\n",
    "\n",
    "drop_yrs = [1982, 1999, 2005, 2006]\n",
    "years = list(range(1980,2024))\n",
    "yrs = [y for y in years if y not in drop_yrs]\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "for year in yrs:\n",
    "    df_test = df[df['Year'] == year] # create test dataframe of one year\n",
    "    years1 = list(range(1980,2024))\n",
    "    yrs1 = [y for y in years1 if y not in drop_yrs]\n",
    "    yrs1.remove(year) # remove test year from list\n",
    "    valid_years = random.sample(yrs1, 4) # generate 4 random years for validation data\n",
    "    df_valid = df[df['Year'].isin(valid_years)] # create validation dataframe\n",
    "    df_train = df[~df['Year'].isin([year] + list(valid_years))] # training dataframe with remaining years\n",
    "    X_test =  df_test[cols]\n",
    "    y_test = df_test['Share']\n",
    "    X_valid =  df_valid[cols]\n",
    "    y_valid = df_valid['Share']\n",
    "    X_train = df_train[cols]\n",
    "    y_train = df_train['Share']\n",
    "    train_model(X_train, y_train, X_valid, y_valid)\n",
    "    pred = model(X_test)                       \n",
    "    eval, results = evaluate(y_test, pred)\n",
    "    evals_by_year[year] = eval\n",
    "    results_by_year[year] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MVP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-0.087821</td>\n",
       "      <td>0.088366</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.793446</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.717219</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.653487</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.920397</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.726747</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.438344</td>\n",
       "      <td>0.049825</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.550228</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.308159</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>-0.236860</td>\n",
       "      <td>0.125753</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>0.862393</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.336131</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.370947</td>\n",
       "      <td>0.032366</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.362211</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.610398</td>\n",
       "      <td>0.026466</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.658681</td>\n",
       "      <td>0.027348</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.452493</td>\n",
       "      <td>0.046117</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.788317</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.337498</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.844940</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.611981</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.942031</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.421365</td>\n",
       "      <td>0.047497</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.538052</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.313970</td>\n",
       "      <td>0.057754</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.236975</td>\n",
       "      <td>0.063762</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.726206</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.379315</td>\n",
       "      <td>0.059989</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.886711</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.690662</td>\n",
       "      <td>0.029672</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.415201</td>\n",
       "      <td>0.054006</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.755833</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.839836</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.885293</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.894081</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.712193</td>\n",
       "      <td>0.028473</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.633586</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.364618</td>\n",
       "      <td>0.060932</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.630222</td>\n",
       "      <td>0.037461</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2       MSE      MVP\n",
       "Idx                              \n",
       "1983 -0.087821  0.088366    Wrong\n",
       "1989  0.793446  0.015315    Wrong\n",
       "1993  0.717219  0.027142    Wrong\n",
       "1994  0.653487  0.031883    Wrong\n",
       "1997  0.920397  0.007517    Wrong\n",
       "1998  0.726747  0.027557    Wrong\n",
       "2001  0.438344  0.049825    Wrong\n",
       "2008  0.550228  0.045166    Wrong\n",
       "2011  0.308159  0.062978    Wrong\n",
       "2017 -0.236860  0.125753    Wrong\n",
       "2023  0.862393  0.014684    Wrong\n",
       "1980  0.336131  0.026826  Correct\n",
       "1981  0.370947  0.032366  Correct\n",
       "1984  0.362211  0.039560  Correct\n",
       "1985  0.610398  0.026466  Correct\n",
       "1986  0.658681  0.027348  Correct\n",
       "1987  0.452493  0.046117  Correct\n",
       "1988  0.788317  0.019067  Correct\n",
       "1990  0.337498  0.048404  Correct\n",
       "1991  0.844940  0.012842  Correct\n",
       "1992  0.611981  0.031332  Correct\n",
       "1995  0.942031  0.004351  Correct\n",
       "1996  0.421365  0.047497  Correct\n",
       "2000  0.538052  0.032275  Correct\n",
       "2002  0.313970  0.057754  Correct\n",
       "2003  0.236975  0.063762  Correct\n",
       "2004  0.726206  0.025584  Correct\n",
       "2007  0.379315  0.059989  Correct\n",
       "2009  0.886711  0.011478  Correct\n",
       "2010  0.690662  0.029672  Correct\n",
       "2012  0.415201  0.054006  Correct\n",
       "2013  0.755833  0.023800  Correct\n",
       "2014  0.839836  0.016585  Correct\n",
       "2015  0.885293  0.011247  Correct\n",
       "2016  0.460810  0.051163  Correct\n",
       "2018  0.894081  0.010899  Correct\n",
       "2019  0.712193  0.028473  Correct\n",
       "2020  0.633586  0.036602  Correct\n",
       "2021  0.364618  0.060932  Correct\n",
       "2022  0.630222  0.037461  Correct"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3_res = pd.DataFrame(list(evals_by_year.values()), index=evals_by_year.keys())\n",
    "nn3_res.columns = ['R2', 'MSE', 'MVP']\n",
    "nn3_res.index.name='Idx'\n",
    "nn3_res.sort_values(by = ['MVP', 'Idx'], ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Correct    29\n",
       "Wrong      11\n",
       "Name: MVP, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3_res['MVP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2     0.568657\n",
       "MSE    0.036751\n",
       "dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3_res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Share</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Derrick Rose</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.585454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dwight Howard</th>\n",
       "      <td>0.531</td>\n",
       "      <td>0.204874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeBron James</th>\n",
       "      <td>0.431</td>\n",
       "      <td>0.777740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kobe Bryant</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.126026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kevin Durant</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.169855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dirk Nowitzki</th>\n",
       "      <td>0.093</td>\n",
       "      <td>0.062743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dwyane Wade</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.463598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manu Ginóbili</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.010671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amar'e Stoudemire</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blake Griffin</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Share  prediction\n",
       "Player                              \n",
       "Derrick Rose       0.977    0.585454\n",
       "Dwight Howard      0.531    0.204874\n",
       "LeBron James       0.431    0.777740\n",
       "Kobe Bryant        0.354    0.126026\n",
       "Kevin Durant       0.157    0.169855\n",
       "Dirk Nowitzki      0.093    0.062743\n",
       "Dwyane Wade        0.020    0.463598\n",
       "Manu Ginóbili      0.017    0.010671\n",
       "Amar'e Stoudemire  0.007    0.006265\n",
       "Blake Griffin      0.004    0.000938"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_by_year[2011]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with entire data, save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_valid, y_valid):\n",
    "    tf.random.set_seed(42)\n",
    "    norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "    model = tf.keras.Sequential([\n",
    "        norm_layer,\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=8e-3)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "    norm_layer.adapt(X_train)\n",
    "    history = model.fit(X_train, y_train, epochs=30,\n",
    "                        validation_data=(X_valid,y_valid),\n",
    "                        callbacks=callbacks\n",
    "                        )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 3s 36ms/step - loss: 0.0619 - root_mean_squared_error: 0.2487 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1975\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0376 - root_mean_squared_error: 0.1939 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0311 - root_mean_squared_error: 0.1763 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1889\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1885\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0270 - root_mean_squared_error: 0.1642 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0248 - root_mean_squared_error: 0.1576 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1719\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0213 - root_mean_squared_error: 0.1458 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1763\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0208 - root_mean_squared_error: 0.1442 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0207 - root_mean_squared_error: 0.1439 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0191 - root_mean_squared_error: 0.1380 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0167 - root_mean_squared_error: 0.1291 - val_loss: 0.0367 - val_root_mean_squared_error: 0.1916\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0175 - root_mean_squared_error: 0.1321 - val_loss: 0.0492 - val_root_mean_squared_error: 0.2217\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0215 - root_mean_squared_error: 0.1467 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1776\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0144 - root_mean_squared_error: 0.1199 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1871\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0135 - root_mean_squared_error: 0.1163 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 35ms/step - loss: 0.0621 - root_mean_squared_error: 0.2492 - val_loss: 0.0641 - val_root_mean_squared_error: 0.2531\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0346 - root_mean_squared_error: 0.1860 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2069\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0325 - root_mean_squared_error: 0.1802 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0268 - root_mean_squared_error: 0.1637 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0239 - root_mean_squared_error: 0.1546 - val_loss: 0.0471 - val_root_mean_squared_error: 0.2171\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0215 - root_mean_squared_error: 0.1467 - val_loss: 0.0476 - val_root_mean_squared_error: 0.2182\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0199 - root_mean_squared_error: 0.1412 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2069\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0173 - root_mean_squared_error: 0.1315 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2021\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2203\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0206 - root_mean_squared_error: 0.1435 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2176\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0163 - root_mean_squared_error: 0.1276 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2117\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0148 - root_mean_squared_error: 0.1216 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2087\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0140 - root_mean_squared_error: 0.1184 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2109\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0141 - root_mean_squared_error: 0.1186 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2133\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0129 - root_mean_squared_error: 0.1135 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2253\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.0748 - root_mean_squared_error: 0.2736 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1793\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0413 - root_mean_squared_error: 0.2032 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1599\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1475\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0266 - root_mean_squared_error: 0.1632 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1416\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0217 - root_mean_squared_error: 0.1475 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0210 - root_mean_squared_error: 0.1450 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0202 - root_mean_squared_error: 0.1421 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0165 - root_mean_squared_error: 0.1286 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0182 - root_mean_squared_error: 0.1348 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0145 - root_mean_squared_error: 0.1202 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1614\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0140 - root_mean_squared_error: 0.1184 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0143 - root_mean_squared_error: 0.1197 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.1606 - root_mean_squared_error: 0.4007 - val_loss: 0.1563 - val_root_mean_squared_error: 0.3953\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0898 - root_mean_squared_error: 0.2997 - val_loss: 0.0579 - val_root_mean_squared_error: 0.2407\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0420 - root_mean_squared_error: 0.2050 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2290\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0331 - root_mean_squared_error: 0.1819 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1992\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0273 - root_mean_squared_error: 0.1652 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2016\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0251 - root_mean_squared_error: 0.1583 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1971\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2192\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2065\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0167 - root_mean_squared_error: 0.1293 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1943\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0169 - root_mean_squared_error: 0.1301 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2113\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2074\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 36ms/step - loss: 0.0597 - root_mean_squared_error: 0.2444 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1914\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0410 - root_mean_squared_error: 0.2025 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1864\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0395 - root_mean_squared_error: 0.1988 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1902\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0296 - root_mean_squared_error: 0.1721 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0240 - root_mean_squared_error: 0.1549 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0218 - root_mean_squared_error: 0.1476 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1785\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1768\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1778\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0179 - root_mean_squared_error: 0.1336 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1791\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1799\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0151 - root_mean_squared_error: 0.1229 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0158 - root_mean_squared_error: 0.1258 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1818\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0134 - root_mean_squared_error: 0.1158 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0142 - root_mean_squared_error: 0.1190 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1821\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0139 - root_mean_squared_error: 0.1179 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0127 - root_mean_squared_error: 0.1125 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1849\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0107 - root_mean_squared_error: 0.1037 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1663\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0104 - root_mean_squared_error: 0.1021 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0089 - root_mean_squared_error: 0.0943 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1796\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1710\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0093 - root_mean_squared_error: 0.0964 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n"
     ]
    }
   ],
   "source": [
    "num_models = 5\n",
    "trained_models = []\n",
    "\n",
    "save_folder = 'NN_models'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "for i in range(num_models):\n",
    "    valid_years = random.sample(yrs, 5)\n",
    "    df_valid = df[df['Year'].isin(valid_years)]\n",
    "    df_train = df[~df['Year'].isin(valid_years)]\n",
    "    X_valid = df_valid[cols]\n",
    "    y_valid = df_valid['Share']\n",
    "    X_train = df_train[cols]\n",
    "    y_train = df_train['Share']\n",
    "\n",
    "    model = train_model(X_train, y_train, X_valid, y_valid)\n",
    "    trained_models.append(model)\n",
    "\n",
    "    model.save(os.path.join(save_folder, f'model_{i + 1}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dict of best results\n",
    "filehandler = open('nn_results_year.pkl', 'wb')\n",
    "pickle.dump(results_by_year, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE and Selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fine-tune hyperparameters\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(norm_layer)\n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer,\n",
    "                  metrics=[\"RootMeanSquaredError\"])\n",
    "    norm_layer.adapt(X_train)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 04s]\n",
      "val_root_mean_squared_error: 0.3771508038043976\n",
      "\n",
      "Best val_root_mean_squared_error So Far: 0.15399572253227234\n",
      "Total elapsed time: 00h 00m 23s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 0.0435 - root_mean_squared_error: 0.2086\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0405 - root_mean_squared_error: 0.2011\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0385 - root_mean_squared_error: 0.1961\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0361 - root_mean_squared_error: 0.1901\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0364 - root_mean_squared_error: 0.1907\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0348 - root_mean_squared_error: 0.1865\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0341 - root_mean_squared_error: 0.1847\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0332 - root_mean_squared_error: 0.1822\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0325 - root_mean_squared_error: 0.1802\n",
      "1/1 [==============================] - 0s 201ms/step\n"
     ]
    }
   ],
   "source": [
    "# empty dict to store results\n",
    "evals_by_year = {}\n",
    "\n",
    "best_hps_year={}\n",
    "\n",
    "results_by_year = {}\n",
    "\n",
    "drop_yrs = [1982, 1999, 2005, 2006]\n",
    "years = list(range(1980,2024))\n",
    "yrs = [y for y in years if y not in drop_yrs]\n",
    "\n",
    "for year in yrs:\n",
    "    df_test = df[df['Year'] == year] # create test dataframe of one year\n",
    "    years1 = list(range(1980,2024))\n",
    "    yrs1 = [y for y in years1 if y not in drop_yrs]\n",
    "    yrs1.remove(year) # remove test year from list\n",
    "    valid_years = random.sample(yrs1, 3) # generate 3 random years for validation data\n",
    "    df_valid = df[df['Year'].isin(valid_years)] # create validation dataframe\n",
    "    df_train = df[~df['Year'].isin([year] + list(valid_years))] # training dataframe with remaining years\n",
    "    X_test =  df_test[cols]\n",
    "    y_test = df_test['Share']\n",
    "    X_valid =  df_valid[cols]\n",
    "    y_valid = df_valid['Share']\n",
    "    X_train = df_train[cols]\n",
    "    y_train = df_train['Share']\n",
    "    random_search_tuner = kt.RandomSearch(build_model, objective=kt.Objective(\"val_root_mean_squared_error\", direction=\"min\"), \n",
    "        max_trials=5, overwrite=True, directory=\"my_mvp\", project_name=\"my_rnd_search\", seed=42)\n",
    "    random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))\n",
    "    best_model = random_search_tuner.get_best_models(num_models=1)[0]\n",
    "    #best_model = top2_models[0]\n",
    "    best_model.fit(X_train, y_train, epochs=10)\n",
    "    pred = best_model.predict(X_test)                       \n",
    "    eval, results = evaluate(y_test, pred)\n",
    "    evals_by_year[year] = eval\n",
    "    results_by_year[year] = results\n",
    "    best_hps = random_search_tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "    #best_hps = top3_hps[0].values    \n",
    "    best_hps_year[year] = list(best_hps.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MVP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>-0.062162</td>\n",
       "      <td>0.054651</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-0.235494</td>\n",
       "      <td>0.100362</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>-0.203138</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.309105</td>\n",
       "      <td>0.062232</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.149290</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.227498</td>\n",
       "      <td>0.056441</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.491265</td>\n",
       "      <td>0.048829</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.515250</td>\n",
       "      <td>0.045775</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>-0.662953</td>\n",
       "      <td>0.147523</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>-0.087257</td>\n",
       "      <td>0.091531</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.095131</td>\n",
       "      <td>0.075615</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.685206</td>\n",
       "      <td>0.031612</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>-0.416668</td>\n",
       "      <td>0.128958</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>-0.412347</td>\n",
       "      <td>0.143595</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>0.741059</td>\n",
       "      <td>0.027631</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.446455</td>\n",
       "      <td>0.022368</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.622125</td>\n",
       "      <td>0.025670</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.730638</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.734240</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.542147</td>\n",
       "      <td>0.037919</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.667161</td>\n",
       "      <td>0.026876</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.711164</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.835164</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.275410</td>\n",
       "      <td>0.059477</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.566504</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.610226</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.767683</td>\n",
       "      <td>0.021708</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.260850</td>\n",
       "      <td>0.071439</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.477567</td>\n",
       "      <td>0.052929</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.655097</td>\n",
       "      <td>0.033084</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.235378</td>\n",
       "      <td>0.070613</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.631678</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.379521</td>\n",
       "      <td>0.064250</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.645108</td>\n",
       "      <td>0.034796</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.611155</td>\n",
       "      <td>0.036897</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.748654</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.548237</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.407895</td>\n",
       "      <td>0.059146</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.594165</td>\n",
       "      <td>0.038919</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.524876</td>\n",
       "      <td>0.048133</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2       MSE      MVP\n",
       "Idx                              \n",
       "1981 -0.062162  0.054651    Wrong\n",
       "1983 -0.235494  0.100362    Wrong\n",
       "1984 -0.203138  0.074627    Wrong\n",
       "1988  0.309105  0.062232    Wrong\n",
       "1989  0.149290  0.063074    Wrong\n",
       "1990  0.227498  0.056441    Wrong\n",
       "1993  0.491265  0.048829    Wrong\n",
       "1997  0.515250  0.045775    Wrong\n",
       "2001 -0.662953  0.147523    Wrong\n",
       "2002 -0.087257  0.091531    Wrong\n",
       "2003  0.095131  0.075615    Wrong\n",
       "2008  0.685206  0.031612    Wrong\n",
       "2011 -0.416668  0.128958    Wrong\n",
       "2017 -0.412347  0.143595    Wrong\n",
       "2023  0.741059  0.027631    Wrong\n",
       "1980  0.446455  0.022368  Correct\n",
       "1985  0.622125  0.025670  Correct\n",
       "1986  0.730638  0.021583  Correct\n",
       "1987  0.734240  0.022385  Correct\n",
       "1991  0.542147  0.037919  Correct\n",
       "1992  0.667161  0.026876  Correct\n",
       "1994  0.711164  0.026576  Correct\n",
       "1995  0.835164  0.012373  Correct\n",
       "1996  0.275410  0.059477  Correct\n",
       "1998  0.566504  0.043716  Correct\n",
       "2000  0.610226  0.027233  Correct\n",
       "2004  0.767683  0.021708  Correct\n",
       "2007  0.260850  0.071439  Correct\n",
       "2009  0.477567  0.052929  Correct\n",
       "2010  0.655097  0.033084  Correct\n",
       "2012  0.235378  0.070613  Correct\n",
       "2013  0.631678  0.035903  Correct\n",
       "2014  0.379521  0.064250  Correct\n",
       "2015  0.645108  0.034796  Correct\n",
       "2016  0.611155  0.036897  Correct\n",
       "2018  0.748654  0.025864  Correct\n",
       "2019  0.548237  0.044693  Correct\n",
       "2020  0.407895  0.059146  Correct\n",
       "2021  0.594165  0.038919  Correct\n",
       "2022  0.524876  0.048133  Correct"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2_res = pd.DataFrame(list(evals_by_year.values()), index=evals_by_year.keys())\n",
    "nn2_res.columns = ['R2', 'MSE', 'MVP']\n",
    "nn2_res.index.name='Idx'\n",
    "nn2_res.sort_values(by = ['MVP', 'Idx'], ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Correct    25\n",
       "Wrong      15\n",
       "Name: MVP, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2_res['MVP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2     0.384072\n",
       "MSE    0.052925\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2_res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1         2     3\n",
       "1980  4   74  0.009051  adam\n",
       "1981  8   37  0.008547   sgd\n",
       "1983  4   74  0.009051  adam\n",
       "1984  8   37  0.008547   sgd\n",
       "1985  4   74  0.009051  adam\n",
       "1986  4   74  0.009051  adam\n",
       "1987  8   37  0.008547   sgd\n",
       "1988  4   74  0.009051  adam\n",
       "1989  4   74  0.009051  adam\n",
       "1990  4   74  0.009051  adam\n",
       "1991  4   74  0.009051  adam\n",
       "1992  8   37  0.008547   sgd\n",
       "1993  4   74  0.009051  adam\n",
       "1994  4   74  0.009051  adam\n",
       "1995  4   74  0.009051  adam\n",
       "1996  4   74  0.009051  adam\n",
       "1997  4   74  0.009051  adam\n",
       "1998  8   37  0.008547   sgd\n",
       "2000  4   74  0.009051  adam\n",
       "2001  4   74  0.009051  adam\n",
       "2002  8   37  0.008547   sgd\n",
       "2003  4   74  0.009051  adam\n",
       "2004  4   74  0.009051  adam\n",
       "2007  4   74  0.009051  adam\n",
       "2008  4   74  0.009051  adam\n",
       "2009  8   37  0.008547   sgd\n",
       "2010  4   74  0.009051  adam\n",
       "2011  7  100  0.001248   sgd\n",
       "2012  4   74  0.009051  adam\n",
       "2013  8   37  0.008547   sgd\n",
       "2014  4   74  0.009051  adam\n",
       "2015  8   37  0.008547   sgd\n",
       "2016  4   74  0.009051  adam\n",
       "2017  4   74  0.009051  adam\n",
       "2018  4   74  0.009051  adam\n",
       "2019  4   74  0.009051  adam\n",
       "2020  8   37  0.008547   sgd\n",
       "2021  4   74  0.009051  adam\n",
       "2022  4   74  0.009051  adam\n",
       "2023  8   37  0.008547   sgd"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = pd.DataFrame(list(best_hps_year.values()), index=best_hps_year.keys())\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    28\n",
      "8    11\n",
      "7     1\n",
      "Name: 0, dtype: int64\n",
      "74     28\n",
      "37     11\n",
      "100     1\n",
      "Name: 1, dtype: int64\n",
      "0.009051    28\n",
      "0.008547    11\n",
      "0.001248     1\n",
      "Name: 2, dtype: int64\n",
      "adam    28\n",
      "sgd     12\n",
      "Name: 3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in best_hps.columns:\n",
    "    print(best_hps[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test using best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impelement early stopping\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"selu_mse1\",\n",
    "                                                         save_best_only=True)\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = Path() / \"selu_mse1\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 2s 22ms/step - loss: 7.4989 - root_mean_squared_error: 2.7384 - val_loss: 1.8480 - val_root_mean_squared_error: 1.3594\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.9792 - root_mean_squared_error: 0.9896 - val_loss: 1.7454 - val_root_mean_squared_error: 1.3211\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5466 - root_mean_squared_error: 0.7393 - val_loss: 0.4281 - val_root_mean_squared_error: 0.6543\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3471 - root_mean_squared_error: 0.5891 - val_loss: 0.3688 - val_root_mean_squared_error: 0.6073\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4834 - root_mean_squared_error: 0.6953 - val_loss: 0.6720 - val_root_mean_squared_error: 0.8198\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4327 - root_mean_squared_error: 0.6578 - val_loss: 0.4823 - val_root_mean_squared_error: 0.6945\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3245 - root_mean_squared_error: 0.5697 - val_loss: 0.3123 - val_root_mean_squared_error: 0.5588\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1189 - root_mean_squared_error: 0.3448 - val_loss: 0.1782 - val_root_mean_squared_error: 0.4221\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0769 - root_mean_squared_error: 0.2773 - val_loss: 0.0918 - val_root_mean_squared_error: 0.3030\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0759 - root_mean_squared_error: 0.2754 - val_loss: 0.0959 - val_root_mean_squared_error: 0.3097\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0625 - val_root_mean_squared_error: 0.2499\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0326 - root_mean_squared_error: 0.1805 - val_loss: 0.0695 - val_root_mean_squared_error: 0.2636\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2409\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0293 - root_mean_squared_error: 0.1712 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1874\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2583\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0254 - root_mean_squared_error: 0.1594 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1989\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0230 - root_mean_squared_error: 0.1518 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2184\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0247 - root_mean_squared_error: 0.1573 - val_loss: 0.0545 - val_root_mean_squared_error: 0.2334\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0217 - root_mean_squared_error: 0.1473 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2036\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1909\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 1s 26ms/step - loss: 5.6426 - root_mean_squared_error: 2.3754 - val_loss: 0.6316 - val_root_mean_squared_error: 0.7947\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6174 - root_mean_squared_error: 0.7857 - val_loss: 0.6006 - val_root_mean_squared_error: 0.7750\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3296 - root_mean_squared_error: 0.5741 - val_loss: 1.2312 - val_root_mean_squared_error: 1.1096\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5267 - root_mean_squared_error: 0.7257 - val_loss: 0.5748 - val_root_mean_squared_error: 0.7581\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2866 - root_mean_squared_error: 0.5354 - val_loss: 0.1556 - val_root_mean_squared_error: 0.3945\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1187 - root_mean_squared_error: 0.3445 - val_loss: 0.1761 - val_root_mean_squared_error: 0.4196\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1600 - root_mean_squared_error: 0.4000 - val_loss: 0.0777 - val_root_mean_squared_error: 0.2787\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0774 - root_mean_squared_error: 0.2782 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2547\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0451 - root_mean_squared_error: 0.2124 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2450\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0321 - root_mean_squared_error: 0.1793 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0305 - root_mean_squared_error: 0.1746 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2192\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0296 - root_mean_squared_error: 0.1721 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1992\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0266 - root_mean_squared_error: 0.1631 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2397\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0414 - root_mean_squared_error: 0.2034 - val_loss: 0.0712 - val_root_mean_squared_error: 0.2668\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0276 - root_mean_squared_error: 0.1661 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2060\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0271 - root_mean_squared_error: 0.1647 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2141\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0297 - root_mean_squared_error: 0.1722 - val_loss: 0.0411 - val_root_mean_squared_error: 0.2028\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2523\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0290 - root_mean_squared_error: 0.1703 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2227\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 24ms/step - loss: 6.8725 - root_mean_squared_error: 2.6215 - val_loss: 3.0202 - val_root_mean_squared_error: 1.7379\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.6121 - root_mean_squared_error: 1.2697 - val_loss: 1.0546 - val_root_mean_squared_error: 1.0269\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3755 - root_mean_squared_error: 0.6127 - val_loss: 0.2221 - val_root_mean_squared_error: 0.4713\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1699 - root_mean_squared_error: 0.4122 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2099\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1001 - root_mean_squared_error: 0.3163 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2472\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0566 - root_mean_squared_error: 0.2378 - val_loss: 0.0789 - val_root_mean_squared_error: 0.2808\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0349 - root_mean_squared_error: 0.1867 - val_loss: 0.0850 - val_root_mean_squared_error: 0.2916\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699 - val_loss: 0.0529 - val_root_mean_squared_error: 0.2300\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0263 - root_mean_squared_error: 0.1622 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2203\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0281 - root_mean_squared_error: 0.1678 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2264\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0255 - root_mean_squared_error: 0.1598 - val_loss: 0.0570 - val_root_mean_squared_error: 0.2387\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 24ms/step - loss: 6.8725 - root_mean_squared_error: 2.6215 - val_loss: 3.7927 - val_root_mean_squared_error: 1.9475\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.6121 - root_mean_squared_error: 1.2697 - val_loss: 1.1913 - val_root_mean_squared_error: 1.0915\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3755 - root_mean_squared_error: 0.6127 - val_loss: 0.1942 - val_root_mean_squared_error: 0.4407\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1699 - root_mean_squared_error: 0.4122 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2525\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1001 - root_mean_squared_error: 0.3163 - val_loss: 0.0838 - val_root_mean_squared_error: 0.2895\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0566 - root_mean_squared_error: 0.2378 - val_loss: 0.0728 - val_root_mean_squared_error: 0.2697\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0349 - root_mean_squared_error: 0.1867 - val_loss: 0.0833 - val_root_mean_squared_error: 0.2886\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699 - val_loss: 0.0642 - val_root_mean_squared_error: 0.2533\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0263 - root_mean_squared_error: 0.1622 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2252\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0281 - root_mean_squared_error: 0.1678 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2468\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1598 - val_loss: 0.0631 - val_root_mean_squared_error: 0.2512\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0272 - root_mean_squared_error: 0.1648 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2514\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0841 - val_root_mean_squared_error: 0.2899\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0841 - val_root_mean_squared_error: 0.2900\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0356 - root_mean_squared_error: 0.1886 - val_loss: 0.0829 - val_root_mean_squared_error: 0.2879\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0431 - root_mean_squared_error: 0.2077 - val_loss: 0.0906 - val_root_mean_squared_error: 0.3009\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 24ms/step - loss: 7.9390 - root_mean_squared_error: 2.8176 - val_loss: 1.2426 - val_root_mean_squared_error: 1.1147\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8983 - root_mean_squared_error: 0.9478 - val_loss: 0.4071 - val_root_mean_squared_error: 0.6380\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4899 - root_mean_squared_error: 0.7000 - val_loss: 0.2888 - val_root_mean_squared_error: 0.5374\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3322 - root_mean_squared_error: 0.5764 - val_loss: 0.1134 - val_root_mean_squared_error: 0.3368\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2327 - root_mean_squared_error: 0.4824 - val_loss: 0.0848 - val_root_mean_squared_error: 0.2912\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2101 - root_mean_squared_error: 0.4584 - val_loss: 0.3800 - val_root_mean_squared_error: 0.6164\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1362 - root_mean_squared_error: 0.3691 - val_loss: 0.2550 - val_root_mean_squared_error: 0.5049\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0875 - root_mean_squared_error: 0.2958 - val_loss: 0.0781 - val_root_mean_squared_error: 0.2794\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0356 - root_mean_squared_error: 0.1887 - val_loss: 0.0714 - val_root_mean_squared_error: 0.2672\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - val_loss: 0.0571 - val_root_mean_squared_error: 0.2389\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0300 - root_mean_squared_error: 0.1733 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2508\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0303 - root_mean_squared_error: 0.1739 - val_loss: 0.0928 - val_root_mean_squared_error: 0.3046\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0306 - root_mean_squared_error: 0.1748 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0301 - root_mean_squared_error: 0.1735 - val_loss: 0.0672 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0331 - root_mean_squared_error: 0.1819 - val_loss: 0.0647 - val_root_mean_squared_error: 0.2544\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0244 - root_mean_squared_error: 0.1563 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0260 - root_mean_squared_error: 0.1614 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0249 - root_mean_squared_error: 0.1577 - val_loss: 0.0815 - val_root_mean_squared_error: 0.2855\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0261 - root_mean_squared_error: 0.1615 - val_loss: 0.0688 - val_root_mean_squared_error: 0.2624\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0302 - root_mean_squared_error: 0.1739 - val_loss: 0.0657 - val_root_mean_squared_error: 0.2562\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - root_mean_squared_error: 0.1542 - val_loss: 0.0695 - val_root_mean_squared_error: 0.2636\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0206 - root_mean_squared_error: 0.1435 - val_loss: 0.0729 - val_root_mean_squared_error: 0.2701\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0240 - root_mean_squared_error: 0.1550 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2545\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 24ms/step - loss: 6.0290 - root_mean_squared_error: 2.4554 - val_loss: 1.7329 - val_root_mean_squared_error: 1.3164\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8916 - root_mean_squared_error: 0.9443 - val_loss: 0.6527 - val_root_mean_squared_error: 0.8079\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3446 - root_mean_squared_error: 0.5871 - val_loss: 0.3320 - val_root_mean_squared_error: 0.5762\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.2069 - root_mean_squared_error: 0.4548 - val_loss: 0.1518 - val_root_mean_squared_error: 0.3897\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1346 - root_mean_squared_error: 0.3668 - val_loss: 0.1654 - val_root_mean_squared_error: 0.4066\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0797 - root_mean_squared_error: 0.2824 - val_loss: 0.1154 - val_root_mean_squared_error: 0.3397\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0626 - root_mean_squared_error: 0.2503 - val_loss: 0.1122 - val_root_mean_squared_error: 0.3349\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0831 - val_root_mean_squared_error: 0.2882\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0282 - root_mean_squared_error: 0.1680 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2477\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0709 - val_root_mean_squared_error: 0.2663\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0338 - root_mean_squared_error: 0.1838 - val_loss: 0.0947 - val_root_mean_squared_error: 0.3078\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0266 - root_mean_squared_error: 0.1632 - val_loss: 0.0895 - val_root_mean_squared_error: 0.2992\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0299 - root_mean_squared_error: 0.1730 - val_loss: 0.0625 - val_root_mean_squared_error: 0.2501\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0624 - val_root_mean_squared_error: 0.2498\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0380 - root_mean_squared_error: 0.1948 - val_loss: 0.1045 - val_root_mean_squared_error: 0.3233\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0307 - root_mean_squared_error: 0.1753 - val_loss: 0.0771 - val_root_mean_squared_error: 0.2776\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 26ms/step - loss: 6.0421 - root_mean_squared_error: 2.4581 - val_loss: 1.0682 - val_root_mean_squared_error: 1.0335\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8038 - root_mean_squared_error: 0.8966 - val_loss: 0.3743 - val_root_mean_squared_error: 0.6118\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.2102 - root_mean_squared_error: 0.4585 - val_loss: 0.3414 - val_root_mean_squared_error: 0.5843\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1209 - root_mean_squared_error: 0.3478 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2330\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0637 - root_mean_squared_error: 0.2525 - val_loss: 0.1032 - val_root_mean_squared_error: 0.3212\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0476 - root_mean_squared_error: 0.2181 - val_loss: 0.0825 - val_root_mean_squared_error: 0.2872\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0416 - root_mean_squared_error: 0.2040 - val_loss: 0.0933 - val_root_mean_squared_error: 0.3054\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0503 - root_mean_squared_error: 0.2243 - val_loss: 0.1283 - val_root_mean_squared_error: 0.3582\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0601 - root_mean_squared_error: 0.2452 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2495\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0387 - root_mean_squared_error: 0.1966 - val_loss: 0.0766 - val_root_mean_squared_error: 0.2768\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.1807 - val_root_mean_squared_error: 0.4251\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 35ms/step - loss: 8.6990 - root_mean_squared_error: 2.9494 - val_loss: 2.8787 - val_root_mean_squared_error: 1.6967\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.2191 - root_mean_squared_error: 1.1041 - val_loss: 0.5763 - val_root_mean_squared_error: 0.7591\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4387 - root_mean_squared_error: 0.6624 - val_loss: 0.4133 - val_root_mean_squared_error: 0.6428\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1806 - root_mean_squared_error: 0.4249 - val_loss: 0.1226 - val_root_mean_squared_error: 0.3501\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1255 - root_mean_squared_error: 0.3543 - val_loss: 0.1391 - val_root_mean_squared_error: 0.3729\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1130 - root_mean_squared_error: 0.3362 - val_loss: 0.1646 - val_root_mean_squared_error: 0.4057\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0556 - root_mean_squared_error: 0.2357 - val_loss: 0.0888 - val_root_mean_squared_error: 0.2980\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0403 - root_mean_squared_error: 0.2008 - val_loss: 0.1181 - val_root_mean_squared_error: 0.3436\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0424 - root_mean_squared_error: 0.2058 - val_loss: 0.1091 - val_root_mean_squared_error: 0.3302\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0438 - root_mean_squared_error: 0.2093 - val_loss: 0.0617 - val_root_mean_squared_error: 0.2485\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0361 - root_mean_squared_error: 0.1900 - val_loss: 0.0807 - val_root_mean_squared_error: 0.2842\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0263 - root_mean_squared_error: 0.1622 - val_loss: 0.0739 - val_root_mean_squared_error: 0.2718\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0351 - root_mean_squared_error: 0.1874 - val_loss: 0.0514 - val_root_mean_squared_error: 0.2267\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0558 - root_mean_squared_error: 0.2362 - val_loss: 0.0699 - val_root_mean_squared_error: 0.2644\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0697 - root_mean_squared_error: 0.2639 - val_loss: 0.0962 - val_root_mean_squared_error: 0.3101\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0645 - root_mean_squared_error: 0.2539 - val_loss: 0.0763 - val_root_mean_squared_error: 0.2762\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.1075 - val_root_mean_squared_error: 0.3278\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0311 - root_mean_squared_error: 0.1764 - val_loss: 0.0578 - val_root_mean_squared_error: 0.2404\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0250 - root_mean_squared_error: 0.1581 - val_loss: 0.0871 - val_root_mean_squared_error: 0.2952\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - val_loss: 0.0765 - val_root_mean_squared_error: 0.2766\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 26ms/step - loss: 8.4904 - root_mean_squared_error: 2.9138 - val_loss: 2.5534 - val_root_mean_squared_error: 1.5979\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0938 - root_mean_squared_error: 1.0459 - val_loss: 0.4703 - val_root_mean_squared_error: 0.6858\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3935 - root_mean_squared_error: 0.6273 - val_loss: 0.1507 - val_root_mean_squared_error: 0.3883\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1555 - root_mean_squared_error: 0.3943 - val_loss: 0.0786 - val_root_mean_squared_error: 0.2804\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0733 - root_mean_squared_error: 0.2707 - val_loss: 0.0708 - val_root_mean_squared_error: 0.2661\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0554 - root_mean_squared_error: 0.2353 - val_loss: 0.0914 - val_root_mean_squared_error: 0.3023\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0514 - root_mean_squared_error: 0.2266 - val_loss: 0.0400 - val_root_mean_squared_error: 0.1999\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0531 - root_mean_squared_error: 0.2305 - val_loss: 0.1853 - val_root_mean_squared_error: 0.4305\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0635 - root_mean_squared_error: 0.2520 - val_loss: 0.0657 - val_root_mean_squared_error: 0.2564\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0757 - val_root_mean_squared_error: 0.2751\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0364 - root_mean_squared_error: 0.1909 - val_loss: 0.0675 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0292 - root_mean_squared_error: 0.1708 - val_loss: 0.0367 - val_root_mean_squared_error: 0.1917\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0358 - root_mean_squared_error: 0.1891 - val_loss: 0.0828 - val_root_mean_squared_error: 0.2877\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0438 - root_mean_squared_error: 0.2094 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.1435 - val_root_mean_squared_error: 0.3788\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0507 - root_mean_squared_error: 0.2252 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0752 - val_root_mean_squared_error: 0.2742\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - root_mean_squared_error: 0.1710 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2235\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0302 - root_mean_squared_error: 0.1737 - val_loss: 0.0642 - val_root_mean_squared_error: 0.2534\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 29ms/step - loss: 8.3593 - root_mean_squared_error: 2.8913 - val_loss: 2.6929 - val_root_mean_squared_error: 1.6410\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.1337 - root_mean_squared_error: 1.0647 - val_loss: 0.3161 - val_root_mean_squared_error: 0.5622\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3732 - root_mean_squared_error: 0.6109 - val_loss: 0.2203 - val_root_mean_squared_error: 0.4693\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1235 - root_mean_squared_error: 0.3514 - val_loss: 0.0867 - val_root_mean_squared_error: 0.2945\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0734 - root_mean_squared_error: 0.2709 - val_loss: 0.0863 - val_root_mean_squared_error: 0.2938\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0767 - root_mean_squared_error: 0.2769 - val_loss: 0.1051 - val_root_mean_squared_error: 0.3241\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0533 - root_mean_squared_error: 0.2308 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2456\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0489 - root_mean_squared_error: 0.2210 - val_loss: 0.1008 - val_root_mean_squared_error: 0.3176\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2546\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2455\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0311 - root_mean_squared_error: 0.1765 - val_loss: 0.0767 - val_root_mean_squared_error: 0.2769\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0306 - root_mean_squared_error: 0.1750 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2192\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0716 - val_root_mean_squared_error: 0.2676\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2232\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0355 - root_mean_squared_error: 0.1885 - val_loss: 0.1175 - val_root_mean_squared_error: 0.3428\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0793 - root_mean_squared_error: 0.2817 - val_loss: 0.1220 - val_root_mean_squared_error: 0.3493\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0521 - root_mean_squared_error: 0.2282 - val_loss: 0.1661 - val_root_mean_squared_error: 0.4075\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0644 - root_mean_squared_error: 0.2538 - val_loss: 0.0532 - val_root_mean_squared_error: 0.2307\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0687 - root_mean_squared_error: 0.2621 - val_loss: 0.0720 - val_root_mean_squared_error: 0.2683\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 29ms/step - loss: 8.6786 - root_mean_squared_error: 2.9459 - val_loss: 2.6175 - val_root_mean_squared_error: 1.6179\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.1518 - root_mean_squared_error: 1.0732 - val_loss: 0.3862 - val_root_mean_squared_error: 0.6215\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4776 - root_mean_squared_error: 0.6911 - val_loss: 0.5873 - val_root_mean_squared_error: 0.7664\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.2415 - root_mean_squared_error: 0.4914 - val_loss: 0.0870 - val_root_mean_squared_error: 0.2950\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1478 - root_mean_squared_error: 0.3845 - val_loss: 0.2520 - val_root_mean_squared_error: 0.5020\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0866 - root_mean_squared_error: 0.2942 - val_loss: 0.0843 - val_root_mean_squared_error: 0.2903\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0864 - root_mean_squared_error: 0.2940 - val_loss: 0.1544 - val_root_mean_squared_error: 0.3929\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0629 - root_mean_squared_error: 0.2508 - val_loss: 0.1051 - val_root_mean_squared_error: 0.3242\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0349 - root_mean_squared_error: 0.1868 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2432\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0306 - root_mean_squared_error: 0.1750 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1989\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0282 - root_mean_squared_error: 0.1679 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2412\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0304 - root_mean_squared_error: 0.1744 - val_loss: 0.0706 - val_root_mean_squared_error: 0.2656\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0353 - root_mean_squared_error: 0.1880 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2200\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0454 - root_mean_squared_error: 0.2131 - val_loss: 0.0848 - val_root_mean_squared_error: 0.2913\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0458 - root_mean_squared_error: 0.2141 - val_loss: 0.0704 - val_root_mean_squared_error: 0.2653\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695 - val_loss: 0.0742 - val_root_mean_squared_error: 0.2723\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0249 - root_mean_squared_error: 0.1578 - val_loss: 0.0463 - val_root_mean_squared_error: 0.2152\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 29ms/step - loss: 8.4574 - root_mean_squared_error: 2.9082 - val_loss: 2.0828 - val_root_mean_squared_error: 1.4432\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9521 - root_mean_squared_error: 0.9758 - val_loss: 0.5926 - val_root_mean_squared_error: 0.7698\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3242 - root_mean_squared_error: 0.5694 - val_loss: 0.2838 - val_root_mean_squared_error: 0.5327\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1578 - root_mean_squared_error: 0.3973 - val_loss: 0.1770 - val_root_mean_squared_error: 0.4207\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0801 - root_mean_squared_error: 0.2830 - val_loss: 0.1082 - val_root_mean_squared_error: 0.3290\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0569 - root_mean_squared_error: 0.2385 - val_loss: 0.0935 - val_root_mean_squared_error: 0.3058\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0462 - root_mean_squared_error: 0.2149 - val_loss: 0.0766 - val_root_mean_squared_error: 0.2768\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0526 - root_mean_squared_error: 0.2293 - val_loss: 0.1338 - val_root_mean_squared_error: 0.3657\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0427 - root_mean_squared_error: 0.2066 - val_loss: 0.0672 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0479 - root_mean_squared_error: 0.2188 - val_loss: 0.1200 - val_root_mean_squared_error: 0.3465\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0487 - root_mean_squared_error: 0.2207 - val_loss: 0.0660 - val_root_mean_squared_error: 0.2569\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0471 - root_mean_squared_error: 0.2169 - val_loss: 0.0843 - val_root_mean_squared_error: 0.2903\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0587 - root_mean_squared_error: 0.2423 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0594 - root_mean_squared_error: 0.2437 - val_loss: 0.1504 - val_root_mean_squared_error: 0.3878\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0725 - root_mean_squared_error: 0.2692 - val_loss: 0.0860 - val_root_mean_squared_error: 0.2932\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0645 - root_mean_squared_error: 0.2539 - val_loss: 0.1565 - val_root_mean_squared_error: 0.3956\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0512 - root_mean_squared_error: 0.2262 - val_loss: 0.0645 - val_root_mean_squared_error: 0.2540\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0449 - root_mean_squared_error: 0.2120 - val_loss: 0.1669 - val_root_mean_squared_error: 0.4085\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0811 - val_root_mean_squared_error: 0.2848\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2399\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0281 - root_mean_squared_error: 0.1677 - val_loss: 0.1037 - val_root_mean_squared_error: 0.3221\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2195\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0274 - root_mean_squared_error: 0.1657 - val_loss: 0.0765 - val_root_mean_squared_error: 0.2766\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - root_mean_squared_error: 0.1524 - val_loss: 0.0699 - val_root_mean_squared_error: 0.2644\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - root_mean_squared_error: 0.1521 - val_loss: 0.0904 - val_root_mean_squared_error: 0.3007\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0679 - val_root_mean_squared_error: 0.2605\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0247 - root_mean_squared_error: 0.1572 - val_loss: 0.0909 - val_root_mean_squared_error: 0.3014\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0259 - root_mean_squared_error: 0.1610 - val_loss: 0.1151 - val_root_mean_squared_error: 0.3393\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0275 - root_mean_squared_error: 0.1658 - val_loss: 0.0785 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 27ms/step - loss: 8.5957 - root_mean_squared_error: 2.9318 - val_loss: 2.8245 - val_root_mean_squared_error: 1.6806\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9923 - root_mean_squared_error: 0.9962 - val_loss: 0.4474 - val_root_mean_squared_error: 0.6689\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3404 - root_mean_squared_error: 0.5834 - val_loss: 0.1836 - val_root_mean_squared_error: 0.4284\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1717 - root_mean_squared_error: 0.4144 - val_loss: 0.1380 - val_root_mean_squared_error: 0.3715\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0822 - root_mean_squared_error: 0.2867 - val_loss: 0.0856 - val_root_mean_squared_error: 0.2927\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0560 - root_mean_squared_error: 0.2366 - val_loss: 0.0948 - val_root_mean_squared_error: 0.3079\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0445 - root_mean_squared_error: 0.2110 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2514\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051 - val_loss: 0.1535 - val_root_mean_squared_error: 0.3918\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0395 - root_mean_squared_error: 0.1988 - val_loss: 0.0924 - val_root_mean_squared_error: 0.3040\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0392 - root_mean_squared_error: 0.1979 - val_loss: 0.0886 - val_root_mean_squared_error: 0.2977\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0330 - root_mean_squared_error: 0.1817 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2547\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0344 - root_mean_squared_error: 0.1856 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2416\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0412 - root_mean_squared_error: 0.2029 - val_loss: 0.1254 - val_root_mean_squared_error: 0.3541\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0373 - root_mean_squared_error: 0.1932 - val_loss: 0.0823 - val_root_mean_squared_error: 0.2869\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0272 - root_mean_squared_error: 0.1649 - val_loss: 0.0980 - val_root_mean_squared_error: 0.3131\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0359 - root_mean_squared_error: 0.1895 - val_loss: 0.1012 - val_root_mean_squared_error: 0.3181\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0362 - root_mean_squared_error: 0.1902 - val_loss: 0.0979 - val_root_mean_squared_error: 0.3128\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0327 - root_mean_squared_error: 0.1809 - val_loss: 0.0844 - val_root_mean_squared_error: 0.2905\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0268 - root_mean_squared_error: 0.1636 - val_loss: 0.0887 - val_root_mean_squared_error: 0.2978\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 27ms/step - loss: 8.7553 - root_mean_squared_error: 2.9589 - val_loss: 2.4486 - val_root_mean_squared_error: 1.5648\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9999 - root_mean_squared_error: 0.9999 - val_loss: 0.5331 - val_root_mean_squared_error: 0.7301\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3429 - root_mean_squared_error: 0.5856 - val_loss: 0.2209 - val_root_mean_squared_error: 0.4700\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1546 - root_mean_squared_error: 0.3932 - val_loss: 0.1457 - val_root_mean_squared_error: 0.3817\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0798 - root_mean_squared_error: 0.2824 - val_loss: 0.0821 - val_root_mean_squared_error: 0.2866\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0515 - root_mean_squared_error: 0.2269 - val_loss: 0.0676 - val_root_mean_squared_error: 0.2600\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0440 - root_mean_squared_error: 0.2098 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0425 - root_mean_squared_error: 0.2062 - val_loss: 0.1373 - val_root_mean_squared_error: 0.3705\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0441 - root_mean_squared_error: 0.2099 - val_loss: 0.0737 - val_root_mean_squared_error: 0.2715\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0368 - root_mean_squared_error: 0.1919 - val_loss: 0.0621 - val_root_mean_squared_error: 0.2493\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0299 - root_mean_squared_error: 0.1729 - val_loss: 0.0818 - val_root_mean_squared_error: 0.2860\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0278 - root_mean_squared_error: 0.1666 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2196\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0273 - root_mean_squared_error: 0.1653 - val_loss: 0.0709 - val_root_mean_squared_error: 0.2662\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0271 - root_mean_squared_error: 0.1646 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2545\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0352 - root_mean_squared_error: 0.1876 - val_loss: 0.1162 - val_root_mean_squared_error: 0.3408\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0607 - root_mean_squared_error: 0.2463 - val_loss: 0.1176 - val_root_mean_squared_error: 0.3430\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0395 - root_mean_squared_error: 0.1989 - val_loss: 0.0925 - val_root_mean_squared_error: 0.3041\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0578 - root_mean_squared_error: 0.2404 - val_loss: 0.1211 - val_root_mean_squared_error: 0.3479\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0443 - root_mean_squared_error: 0.2105 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2115\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0264 - root_mean_squared_error: 0.1625 - val_loss: 0.0729 - val_root_mean_squared_error: 0.2700\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0678 - val_root_mean_squared_error: 0.2604\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1928\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0220 - root_mean_squared_error: 0.1484 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2255\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0259 - root_mean_squared_error: 0.1608 - val_loss: 0.0683 - val_root_mean_squared_error: 0.2614\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0800 - val_root_mean_squared_error: 0.2828\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0278 - root_mean_squared_error: 0.1667 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2576\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1953\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0320 - root_mean_squared_error: 0.1789 - val_loss: 0.0642 - val_root_mean_squared_error: 0.2535\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0416 - root_mean_squared_error: 0.2041 - val_loss: 0.2353 - val_root_mean_squared_error: 0.4850\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 73ms/step - loss: 8.7662 - root_mean_squared_error: 2.9608 - val_loss: 2.9810 - val_root_mean_squared_error: 1.7266\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 1.0734 - root_mean_squared_error: 1.0361 - val_loss: 0.9468 - val_root_mean_squared_error: 0.9730\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3599 - root_mean_squared_error: 0.5999 - val_loss: 0.1846 - val_root_mean_squared_error: 0.4297\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1445 - root_mean_squared_error: 0.3801 - val_loss: 0.1475 - val_root_mean_squared_error: 0.3840\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0973 - root_mean_squared_error: 0.3119 - val_loss: 0.0665 - val_root_mean_squared_error: 0.2579\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0566 - root_mean_squared_error: 0.2379 - val_loss: 0.0839 - val_root_mean_squared_error: 0.2897\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0429 - root_mean_squared_error: 0.2071 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0432 - root_mean_squared_error: 0.2078 - val_loss: 0.1207 - val_root_mean_squared_error: 0.3474\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0361 - root_mean_squared_error: 0.1900 - val_loss: 0.1254 - val_root_mean_squared_error: 0.3542\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0443 - root_mean_squared_error: 0.2105 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2337\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0294 - root_mean_squared_error: 0.1714 - val_loss: 0.0670 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0274 - root_mean_squared_error: 0.1656 - val_loss: 0.0534 - val_root_mean_squared_error: 0.2310\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.1076 - val_root_mean_squared_error: 0.3281\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.0833 - val_root_mean_squared_error: 0.2887\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 28ms/step - loss: 5.9264 - root_mean_squared_error: 2.4344 - val_loss: 2.3711 - val_root_mean_squared_error: 1.5398\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.5565 - root_mean_squared_error: 1.2476 - val_loss: 1.2650 - val_root_mean_squared_error: 1.1247\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9509 - root_mean_squared_error: 0.9752 - val_loss: 0.2714 - val_root_mean_squared_error: 0.5210\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5429 - root_mean_squared_error: 0.7368 - val_loss: 0.2164 - val_root_mean_squared_error: 0.4652\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1599 - root_mean_squared_error: 0.3998 - val_loss: 0.1338 - val_root_mean_squared_error: 0.3658\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0672 - root_mean_squared_error: 0.2592 - val_loss: 0.1176 - val_root_mean_squared_error: 0.3429\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0389 - root_mean_squared_error: 0.1972 - val_loss: 0.0796 - val_root_mean_squared_error: 0.2821\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0314 - root_mean_squared_error: 0.1771 - val_loss: 0.1081 - val_root_mean_squared_error: 0.3287\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0665 - val_root_mean_squared_error: 0.2578\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0274 - root_mean_squared_error: 0.1656 - val_loss: 0.0723 - val_root_mean_squared_error: 0.2689\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0782 - val_root_mean_squared_error: 0.2797\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0258 - root_mean_squared_error: 0.1606 - val_loss: 0.0654 - val_root_mean_squared_error: 0.2557\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0230 - root_mean_squared_error: 0.1517 - val_loss: 0.0669 - val_root_mean_squared_error: 0.2586\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0240 - root_mean_squared_error: 0.1550 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2477\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0221 - root_mean_squared_error: 0.1486 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2385\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0215 - root_mean_squared_error: 0.1467 - val_loss: 0.0536 - val_root_mean_squared_error: 0.2314\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0577 - val_root_mean_squared_error: 0.2402\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0222 - root_mean_squared_error: 0.1492 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2566\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0247 - root_mean_squared_error: 0.1571 - val_loss: 0.0774 - val_root_mean_squared_error: 0.2782\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0509 - val_root_mean_squared_error: 0.2257\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0774 - val_root_mean_squared_error: 0.2781\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0269 - root_mean_squared_error: 0.1639 - val_loss: 0.0558 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0193 - root_mean_squared_error: 0.1389 - val_loss: 0.0716 - val_root_mean_squared_error: 0.2675\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0196 - root_mean_squared_error: 0.1399 - val_loss: 0.0562 - val_root_mean_squared_error: 0.2371\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2192\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0248 - root_mean_squared_error: 0.1576 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2431\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0194 - root_mean_squared_error: 0.1393 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0179 - root_mean_squared_error: 0.1337 - val_loss: 0.0719 - val_root_mean_squared_error: 0.2682\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0194 - root_mean_squared_error: 0.1393 - val_loss: 0.0655 - val_root_mean_squared_error: 0.2560\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0850 - val_root_mean_squared_error: 0.2915\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 30ms/step - loss: 8.7636 - root_mean_squared_error: 2.9603 - val_loss: 2.5910 - val_root_mean_squared_error: 1.6096\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0782 - root_mean_squared_error: 1.0384 - val_loss: 0.6276 - val_root_mean_squared_error: 0.7922\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3275 - root_mean_squared_error: 0.5723 - val_loss: 0.2236 - val_root_mean_squared_error: 0.4728\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1481 - root_mean_squared_error: 0.3849 - val_loss: 0.1162 - val_root_mean_squared_error: 0.3408\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0819 - root_mean_squared_error: 0.2861 - val_loss: 0.1630 - val_root_mean_squared_error: 0.4037\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0599 - root_mean_squared_error: 0.2447 - val_loss: 0.0991 - val_root_mean_squared_error: 0.3148\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0585 - root_mean_squared_error: 0.2419 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2576\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0582 - root_mean_squared_error: 0.2413 - val_loss: 0.2877 - val_root_mean_squared_error: 0.5364\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0557 - root_mean_squared_error: 0.2361 - val_loss: 0.0763 - val_root_mean_squared_error: 0.2762\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0423 - root_mean_squared_error: 0.2057 - val_loss: 0.0754 - val_root_mean_squared_error: 0.2745\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0326 - root_mean_squared_error: 0.1806 - val_loss: 0.0704 - val_root_mean_squared_error: 0.2654\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0327 - root_mean_squared_error: 0.1807 - val_loss: 0.0705 - val_root_mean_squared_error: 0.2655\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0354 - root_mean_squared_error: 0.1881 - val_loss: 0.1574 - val_root_mean_squared_error: 0.3967\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.1160 - val_root_mean_squared_error: 0.3407\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 50ms/step - loss: 6.2458 - root_mean_squared_error: 2.4992 - val_loss: 2.0872 - val_root_mean_squared_error: 1.4447\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.3705 - root_mean_squared_error: 1.1707 - val_loss: 1.4001 - val_root_mean_squared_error: 1.1833\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6709 - root_mean_squared_error: 0.8191 - val_loss: 0.6117 - val_root_mean_squared_error: 0.7821\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3421 - root_mean_squared_error: 0.5849 - val_loss: 0.1344 - val_root_mean_squared_error: 0.3667\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1615 - root_mean_squared_error: 0.4019 - val_loss: 0.0954 - val_root_mean_squared_error: 0.3089\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0762 - root_mean_squared_error: 0.2760 - val_loss: 0.0841 - val_root_mean_squared_error: 0.2900\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0420 - root_mean_squared_error: 0.2050 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2074\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0331 - root_mean_squared_error: 0.1820 - val_loss: 0.0555 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0288 - root_mean_squared_error: 0.1697 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2201\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0306 - root_mean_squared_error: 0.1749 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2425\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0276 - root_mean_squared_error: 0.1661 - val_loss: 0.0612 - val_root_mean_squared_error: 0.2474\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0255 - root_mean_squared_error: 0.1598 - val_loss: 0.0523 - val_root_mean_squared_error: 0.2287\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0258 - root_mean_squared_error: 0.1605 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1953\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498 - val_loss: 0.0737 - val_root_mean_squared_error: 0.2714\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0251 - root_mean_squared_error: 0.1585 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2174\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0205 - root_mean_squared_error: 0.1431 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2160\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0250 - root_mean_squared_error: 0.1580 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2142\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0235 - root_mean_squared_error: 0.1533 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2396\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0252 - root_mean_squared_error: 0.1588 - val_loss: 0.0545 - val_root_mean_squared_error: 0.2335\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0223 - root_mean_squared_error: 0.1493 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2159\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 29ms/step - loss: 8.8932 - root_mean_squared_error: 2.9822 - val_loss: 2.1341 - val_root_mean_squared_error: 1.4608\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1001 - root_mean_squared_error: 1.0489 - val_loss: 0.6630 - val_root_mean_squared_error: 0.8143\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3535 - root_mean_squared_error: 0.5945 - val_loss: 0.3782 - val_root_mean_squared_error: 0.6150\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1631 - root_mean_squared_error: 0.4039 - val_loss: 0.1384 - val_root_mean_squared_error: 0.3720\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0911 - root_mean_squared_error: 0.3018 - val_loss: 0.0932 - val_root_mean_squared_error: 0.3053\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0993 - val_root_mean_squared_error: 0.3152\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0423 - root_mean_squared_error: 0.2056 - val_loss: 0.0922 - val_root_mean_squared_error: 0.3037\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0368 - root_mean_squared_error: 0.1918 - val_loss: 0.1248 - val_root_mean_squared_error: 0.3532\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0422 - root_mean_squared_error: 0.2053 - val_loss: 0.1347 - val_root_mean_squared_error: 0.3670\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0475 - root_mean_squared_error: 0.2179 - val_loss: 0.0713 - val_root_mean_squared_error: 0.2670\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0319 - root_mean_squared_error: 0.1785 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2442\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0526 - val_root_mean_squared_error: 0.2294\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0323 - root_mean_squared_error: 0.1798 - val_loss: 0.0947 - val_root_mean_squared_error: 0.3077\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0933 - val_root_mean_squared_error: 0.3054\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0374 - root_mean_squared_error: 0.1933 - val_loss: 0.0631 - val_root_mean_squared_error: 0.2512\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0324 - root_mean_squared_error: 0.1800 - val_loss: 0.0724 - val_root_mean_squared_error: 0.2691\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0615 - val_root_mean_squared_error: 0.2479\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0284 - root_mean_squared_error: 0.1684 - val_loss: 0.0778 - val_root_mean_squared_error: 0.2789\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0291 - root_mean_squared_error: 0.1707 - val_loss: 0.0742 - val_root_mean_squared_error: 0.2725\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 30ms/step - loss: 8.7810 - root_mean_squared_error: 2.9633 - val_loss: 2.6939 - val_root_mean_squared_error: 1.6413\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.1545 - root_mean_squared_error: 1.0745 - val_loss: 0.5390 - val_root_mean_squared_error: 0.7342\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4845 - root_mean_squared_error: 0.6961 - val_loss: 0.3990 - val_root_mean_squared_error: 0.6317\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2087 - root_mean_squared_error: 0.4568 - val_loss: 0.0927 - val_root_mean_squared_error: 0.3045\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0897 - root_mean_squared_error: 0.2995 - val_loss: 0.1210 - val_root_mean_squared_error: 0.3479\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0669 - root_mean_squared_error: 0.2586 - val_loss: 0.1764 - val_root_mean_squared_error: 0.4200\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0509 - root_mean_squared_error: 0.2257 - val_loss: 0.0721 - val_root_mean_squared_error: 0.2685\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0447 - root_mean_squared_error: 0.2114 - val_loss: 0.0634 - val_root_mean_squared_error: 0.2519\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0416 - root_mean_squared_error: 0.2040 - val_loss: 0.0891 - val_root_mean_squared_error: 0.2984\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0464 - root_mean_squared_error: 0.2153 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2582\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0413 - root_mean_squared_error: 0.2032 - val_loss: 0.0842 - val_root_mean_squared_error: 0.2902\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0342 - root_mean_squared_error: 0.1849 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2566\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0373 - root_mean_squared_error: 0.1932 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2524\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0405 - root_mean_squared_error: 0.2013 - val_loss: 0.0784 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0396 - root_mean_squared_error: 0.1990 - val_loss: 0.0540 - val_root_mean_squared_error: 0.2325\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0302 - root_mean_squared_error: 0.1737 - val_loss: 0.1001 - val_root_mean_squared_error: 0.3163\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0360 - root_mean_squared_error: 0.1898 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2424\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0243 - root_mean_squared_error: 0.1559 - val_loss: 0.0963 - val_root_mean_squared_error: 0.3104\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0306 - root_mean_squared_error: 0.1748 - val_loss: 0.0717 - val_root_mean_squared_error: 0.2677\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0379 - root_mean_squared_error: 0.1948 - val_loss: 0.1016 - val_root_mean_squared_error: 0.3188\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0315 - root_mean_squared_error: 0.1774 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2336\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0247 - root_mean_squared_error: 0.1572 - val_loss: 0.0797 - val_root_mean_squared_error: 0.2823\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 8.7541 - root_mean_squared_error: 2.9587 - val_loss: 2.8633 - val_root_mean_squared_error: 1.6921\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1444 - root_mean_squared_error: 1.0697 - val_loss: 0.4202 - val_root_mean_squared_error: 0.6483\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4103 - root_mean_squared_error: 0.6405 - val_loss: 0.2272 - val_root_mean_squared_error: 0.4767\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1657 - root_mean_squared_error: 0.4071 - val_loss: 0.1133 - val_root_mean_squared_error: 0.3366\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1005 - root_mean_squared_error: 0.3170 - val_loss: 0.1463 - val_root_mean_squared_error: 0.3825\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0993 - val_root_mean_squared_error: 0.3151\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0429 - root_mean_squared_error: 0.2070 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2428\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0464 - root_mean_squared_error: 0.2154 - val_loss: 0.1959 - val_root_mean_squared_error: 0.4426\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0485 - root_mean_squared_error: 0.2202 - val_loss: 0.0645 - val_root_mean_squared_error: 0.2540\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - val_loss: 0.0881 - val_root_mean_squared_error: 0.2968\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - val_loss: 0.0698 - val_root_mean_squared_error: 0.2641\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0352 - root_mean_squared_error: 0.1877 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2503\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0422 - root_mean_squared_error: 0.2054 - val_loss: 0.1471 - val_root_mean_squared_error: 0.3835\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0410 - root_mean_squared_error: 0.2025 - val_loss: 0.0935 - val_root_mean_squared_error: 0.3058\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 50ms/step - loss: 8.4675 - root_mean_squared_error: 2.9099 - val_loss: 2.9493 - val_root_mean_squared_error: 1.7173\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.1083 - root_mean_squared_error: 1.0528 - val_loss: 0.2010 - val_root_mean_squared_error: 0.4483\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3608 - root_mean_squared_error: 0.6006 - val_loss: 0.2144 - val_root_mean_squared_error: 0.4630\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.1509 - root_mean_squared_error: 0.3885 - val_loss: 0.1301 - val_root_mean_squared_error: 0.3607\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0731 - root_mean_squared_error: 0.2704 - val_loss: 0.1329 - val_root_mean_squared_error: 0.3646\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0503 - root_mean_squared_error: 0.2243 - val_loss: 0.1202 - val_root_mean_squared_error: 0.3467\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0397 - root_mean_squared_error: 0.1994 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2466\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1589 - val_root_mean_squared_error: 0.3987\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0352 - root_mean_squared_error: 0.1876 - val_loss: 0.0731 - val_root_mean_squared_error: 0.2704\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0321 - root_mean_squared_error: 0.1791 - val_loss: 0.0721 - val_root_mean_squared_error: 0.2685\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0278 - root_mean_squared_error: 0.1666 - val_loss: 0.0661 - val_root_mean_squared_error: 0.2570\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0326 - root_mean_squared_error: 0.1805 - val_loss: 0.0717 - val_root_mean_squared_error: 0.2678\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0355 - root_mean_squared_error: 0.1885 - val_loss: 0.1037 - val_root_mean_squared_error: 0.3220\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0271 - root_mean_squared_error: 0.1646 - val_loss: 0.0776 - val_root_mean_squared_error: 0.2786\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 62ms/step - loss: 8.6690 - root_mean_squared_error: 2.9443 - val_loss: 3.1729 - val_root_mean_squared_error: 1.7813\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1675 - root_mean_squared_error: 1.0805 - val_loss: 0.2470 - val_root_mean_squared_error: 0.4970\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4457 - root_mean_squared_error: 0.6676 - val_loss: 0.2146 - val_root_mean_squared_error: 0.4633\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.1389 - root_mean_squared_error: 0.3727 - val_loss: 0.2088 - val_root_mean_squared_error: 0.4570\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0783 - root_mean_squared_error: 0.2798 - val_loss: 0.0899 - val_root_mean_squared_error: 0.2999\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0491 - root_mean_squared_error: 0.2215 - val_loss: 0.1020 - val_root_mean_squared_error: 0.3193\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0483 - root_mean_squared_error: 0.2197 - val_loss: 0.0483 - val_root_mean_squared_error: 0.2198\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0398 - root_mean_squared_error: 0.1995 - val_loss: 0.1635 - val_root_mean_squared_error: 0.4044\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0948 - val_root_mean_squared_error: 0.3078\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0321 - root_mean_squared_error: 0.1791 - val_loss: 0.0625 - val_root_mean_squared_error: 0.2500\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0350 - root_mean_squared_error: 0.1872 - val_loss: 0.0804 - val_root_mean_squared_error: 0.2835\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0536 - root_mean_squared_error: 0.2314 - val_loss: 0.0972 - val_root_mean_squared_error: 0.3118\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0681 - root_mean_squared_error: 0.2610 - val_loss: 0.2363 - val_root_mean_squared_error: 0.4861\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0798 - root_mean_squared_error: 0.2825 - val_loss: 0.1200 - val_root_mean_squared_error: 0.3464\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 31ms/step - loss: 8.5614 - root_mean_squared_error: 2.9260 - val_loss: 3.4244 - val_root_mean_squared_error: 1.8505\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0667 - root_mean_squared_error: 1.0328 - val_loss: 0.2890 - val_root_mean_squared_error: 0.5376\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4647 - root_mean_squared_error: 0.6817 - val_loss: 0.1495 - val_root_mean_squared_error: 0.3867\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.1558 - root_mean_squared_error: 0.3947 - val_loss: 0.1983 - val_root_mean_squared_error: 0.4453\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0769 - root_mean_squared_error: 0.2772 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3072\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0583 - root_mean_squared_error: 0.2415 - val_loss: 0.1197 - val_root_mean_squared_error: 0.3460\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0466 - root_mean_squared_error: 0.2158 - val_loss: 0.0675 - val_root_mean_squared_error: 0.2598\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0579 - root_mean_squared_error: 0.2406 - val_loss: 0.1288 - val_root_mean_squared_error: 0.3589\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0406 - root_mean_squared_error: 0.2015 - val_loss: 0.0756 - val_root_mean_squared_error: 0.2750\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0512 - root_mean_squared_error: 0.2262 - val_loss: 0.1325 - val_root_mean_squared_error: 0.3640\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0370 - root_mean_squared_error: 0.1923 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2409\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0286 - root_mean_squared_error: 0.1691 - val_loss: 0.0671 - val_root_mean_squared_error: 0.2591\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - val_loss: 0.0680 - val_root_mean_squared_error: 0.2609\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0387 - root_mean_squared_error: 0.1967 - val_loss: 0.1694 - val_root_mean_squared_error: 0.4116\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0564 - root_mean_squared_error: 0.2374 - val_loss: 0.1000 - val_root_mean_squared_error: 0.3163\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0352 - root_mean_squared_error: 0.1876 - val_loss: 0.0811 - val_root_mean_squared_error: 0.2848\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0214 - root_mean_squared_error: 0.1461 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0220 - root_mean_squared_error: 0.1485 - val_loss: 0.0849 - val_root_mean_squared_error: 0.2914\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 28ms/step - loss: 8.3119 - root_mean_squared_error: 2.8830 - val_loss: 2.6891 - val_root_mean_squared_error: 1.6399\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8979 - root_mean_squared_error: 0.9476 - val_loss: 0.4353 - val_root_mean_squared_error: 0.6598\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4267 - root_mean_squared_error: 0.6533 - val_loss: 0.1824 - val_root_mean_squared_error: 0.4271\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1697 - root_mean_squared_error: 0.4119 - val_loss: 0.0948 - val_root_mean_squared_error: 0.3079\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0920 - val_root_mean_squared_error: 0.3034\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0643 - root_mean_squared_error: 0.2535 - val_loss: 0.0843 - val_root_mean_squared_error: 0.2903\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0492 - root_mean_squared_error: 0.2218 - val_loss: 0.0826 - val_root_mean_squared_error: 0.2874\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0588 - root_mean_squared_error: 0.2424 - val_loss: 0.0714 - val_root_mean_squared_error: 0.2672\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0483 - root_mean_squared_error: 0.2197 - val_loss: 0.0551 - val_root_mean_squared_error: 0.2347\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0583 - root_mean_squared_error: 0.2415 - val_loss: 0.1051 - val_root_mean_squared_error: 0.3242\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0430 - root_mean_squared_error: 0.2075 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2578\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2326\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0373 - root_mean_squared_error: 0.1931 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2456\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0434 - root_mean_squared_error: 0.2083 - val_loss: 0.1335 - val_root_mean_squared_error: 0.3653\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0710 - val_root_mean_squared_error: 0.2664\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - root_mean_squared_error: 0.1530 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2413\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0252 - root_mean_squared_error: 0.1586 - val_loss: 0.0847 - val_root_mean_squared_error: 0.2911\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0213 - root_mean_squared_error: 0.1460 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2527\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2385\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 29ms/step - loss: 8.4184 - root_mean_squared_error: 2.9015 - val_loss: 3.1282 - val_root_mean_squared_error: 1.7687\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0526 - root_mean_squared_error: 1.0260 - val_loss: 0.3119 - val_root_mean_squared_error: 0.5585\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4328 - root_mean_squared_error: 0.6578 - val_loss: 0.2097 - val_root_mean_squared_error: 0.4580\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.1634 - root_mean_squared_error: 0.4043 - val_loss: 0.0808 - val_root_mean_squared_error: 0.2843\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0761 - root_mean_squared_error: 0.2758 - val_loss: 0.1255 - val_root_mean_squared_error: 0.3543\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0522 - root_mean_squared_error: 0.2284 - val_loss: 0.0737 - val_root_mean_squared_error: 0.2716\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0489 - val_root_mean_squared_error: 0.2210\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0403 - root_mean_squared_error: 0.2007 - val_loss: 0.0931 - val_root_mean_squared_error: 0.3052\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0419 - root_mean_squared_error: 0.2047 - val_loss: 0.0766 - val_root_mean_squared_error: 0.2768\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0479 - root_mean_squared_error: 0.2188 - val_loss: 0.0895 - val_root_mean_squared_error: 0.2992\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0376 - root_mean_squared_error: 0.1939 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2458\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0413 - root_mean_squared_error: 0.2032 - val_loss: 0.0800 - val_root_mean_squared_error: 0.2829\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0524 - root_mean_squared_error: 0.2289 - val_loss: 0.0714 - val_root_mean_squared_error: 0.2673\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0591 - root_mean_squared_error: 0.2431 - val_loss: 0.1618 - val_root_mean_squared_error: 0.4023\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 29ms/step - loss: 7.2809 - root_mean_squared_error: 2.6983 - val_loss: 2.1636 - val_root_mean_squared_error: 1.4709\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.0167 - root_mean_squared_error: 1.0083 - val_loss: 0.8522 - val_root_mean_squared_error: 0.9231\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4569 - root_mean_squared_error: 0.6760 - val_loss: 0.2922 - val_root_mean_squared_error: 0.5406\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2460 - root_mean_squared_error: 0.4960 - val_loss: 0.1514 - val_root_mean_squared_error: 0.3891\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.1098 - root_mean_squared_error: 0.3314 - val_loss: 0.1233 - val_root_mean_squared_error: 0.3512\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0795 - root_mean_squared_error: 0.2819 - val_loss: 0.1720 - val_root_mean_squared_error: 0.4147\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0715 - root_mean_squared_error: 0.2674 - val_loss: 0.0850 - val_root_mean_squared_error: 0.2916\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0392 - root_mean_squared_error: 0.1981 - val_loss: 0.1093 - val_root_mean_squared_error: 0.3307\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0383 - root_mean_squared_error: 0.1956 - val_loss: 0.1114 - val_root_mean_squared_error: 0.3338\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0432 - root_mean_squared_error: 0.2077 - val_loss: 0.0933 - val_root_mean_squared_error: 0.3055\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0334 - root_mean_squared_error: 0.1828 - val_loss: 0.0661 - val_root_mean_squared_error: 0.2571\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0749 - val_root_mean_squared_error: 0.2736\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0273 - root_mean_squared_error: 0.1653 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2433\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0283 - root_mean_squared_error: 0.1682 - val_loss: 0.0823 - val_root_mean_squared_error: 0.2869\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0219 - root_mean_squared_error: 0.1479 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2466\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0926 - val_root_mean_squared_error: 0.3043\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0346 - root_mean_squared_error: 0.1859 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2374\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - val_loss: 0.0770 - val_root_mean_squared_error: 0.2776\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - root_mean_squared_error: 0.1523 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2524\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0286 - root_mean_squared_error: 0.1691 - val_loss: 0.0802 - val_root_mean_squared_error: 0.2833\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0237 - root_mean_squared_error: 0.1540 - val_loss: 0.0854 - val_root_mean_squared_error: 0.2922\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0769 - val_root_mean_squared_error: 0.2772\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0785 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 3s 47ms/step - loss: 7.9075 - root_mean_squared_error: 2.8120 - val_loss: 2.8133 - val_root_mean_squared_error: 1.6773\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.9435 - root_mean_squared_error: 0.9713 - val_loss: 0.1912 - val_root_mean_squared_error: 0.4373\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3963 - root_mean_squared_error: 0.6296 - val_loss: 0.2173 - val_root_mean_squared_error: 0.4661\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.1459 - root_mean_squared_error: 0.3820 - val_loss: 0.1370 - val_root_mean_squared_error: 0.3702\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0836 - root_mean_squared_error: 0.2891 - val_loss: 0.0815 - val_root_mean_squared_error: 0.2854\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0672 - root_mean_squared_error: 0.2592 - val_loss: 0.0933 - val_root_mean_squared_error: 0.3055\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0423 - root_mean_squared_error: 0.2057 - val_loss: 0.0563 - val_root_mean_squared_error: 0.2374\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0341 - root_mean_squared_error: 0.1848 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2565\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0288 - root_mean_squared_error: 0.1697 - val_loss: 0.0518 - val_root_mean_squared_error: 0.2277\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0323 - root_mean_squared_error: 0.1797 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2441\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - val_loss: 0.0947 - val_root_mean_squared_error: 0.3078\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0295 - root_mean_squared_error: 0.1716 - val_loss: 0.0522 - val_root_mean_squared_error: 0.2285\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0315 - root_mean_squared_error: 0.1774 - val_loss: 0.0788 - val_root_mean_squared_error: 0.2808\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0460 - root_mean_squared_error: 0.2145 - val_loss: 0.0913 - val_root_mean_squared_error: 0.3021\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0324 - root_mean_squared_error: 0.1799 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3072\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0693 - root_mean_squared_error: 0.2633 - val_loss: 0.0900 - val_root_mean_squared_error: 0.3000\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 40ms/step - loss: 7.9075 - root_mean_squared_error: 2.8120 - val_loss: 2.8078 - val_root_mean_squared_error: 1.6756\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.9435 - root_mean_squared_error: 0.9713 - val_loss: 0.2246 - val_root_mean_squared_error: 0.4739\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3963 - root_mean_squared_error: 0.6296 - val_loss: 0.2286 - val_root_mean_squared_error: 0.4781\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.1459 - root_mean_squared_error: 0.3820 - val_loss: 0.1197 - val_root_mean_squared_error: 0.3460\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0836 - root_mean_squared_error: 0.2891 - val_loss: 0.0796 - val_root_mean_squared_error: 0.2821\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0672 - root_mean_squared_error: 0.2592 - val_loss: 0.0843 - val_root_mean_squared_error: 0.2903\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0423 - root_mean_squared_error: 0.2057 - val_loss: 0.0625 - val_root_mean_squared_error: 0.2500\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0341 - root_mean_squared_error: 0.1848 - val_loss: 0.0661 - val_root_mean_squared_error: 0.2571\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0288 - root_mean_squared_error: 0.1697 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0323 - root_mean_squared_error: 0.1797 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - val_loss: 0.0893 - val_root_mean_squared_error: 0.2988\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0295 - root_mean_squared_error: 0.1716 - val_loss: 0.0570 - val_root_mean_squared_error: 0.2388\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0315 - root_mean_squared_error: 0.1774 - val_loss: 0.0837 - val_root_mean_squared_error: 0.2892\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0460 - root_mean_squared_error: 0.2145 - val_loss: 0.0836 - val_root_mean_squared_error: 0.2892\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0324 - root_mean_squared_error: 0.1799 - val_loss: 0.0914 - val_root_mean_squared_error: 0.3023\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0693 - root_mean_squared_error: 0.2633 - val_loss: 0.0896 - val_root_mean_squared_error: 0.2993\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0383 - root_mean_squared_error: 0.1958 - val_loss: 0.0907 - val_root_mean_squared_error: 0.3012\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0355 - root_mean_squared_error: 0.1885 - val_loss: 0.0572 - val_root_mean_squared_error: 0.2391\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0329 - root_mean_squared_error: 0.1814 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2424\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 37ms/step - loss: 7.8096 - root_mean_squared_error: 2.7946 - val_loss: 2.6741 - val_root_mean_squared_error: 1.6353\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9513 - root_mean_squared_error: 0.9753 - val_loss: 0.1377 - val_root_mean_squared_error: 0.3710\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3142 - root_mean_squared_error: 0.5606 - val_loss: 0.1648 - val_root_mean_squared_error: 0.4059\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1183 - root_mean_squared_error: 0.3439 - val_loss: 0.1021 - val_root_mean_squared_error: 0.3195\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0731 - root_mean_squared_error: 0.2704 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2528\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0528 - root_mean_squared_error: 0.2299 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2504\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0472 - root_mean_squared_error: 0.2173 - val_loss: 0.0689 - val_root_mean_squared_error: 0.2625\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0446 - root_mean_squared_error: 0.2111 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0583 - val_root_mean_squared_error: 0.2415\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0291 - root_mean_squared_error: 0.1705 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2565\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670 - val_loss: 0.0519 - val_root_mean_squared_error: 0.2278\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0295 - root_mean_squared_error: 0.1719 - val_loss: 0.0793 - val_root_mean_squared_error: 0.2816\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0293 - root_mean_squared_error: 0.1712 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2448\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0317 - root_mean_squared_error: 0.1780 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2423\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0252 - root_mean_squared_error: 0.1587 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0254 - root_mean_squared_error: 0.1595 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2266\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0548 - val_root_mean_squared_error: 0.2341\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0344 - root_mean_squared_error: 0.1855 - val_loss: 0.0917 - val_root_mean_squared_error: 0.3027\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0391 - root_mean_squared_error: 0.1976 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2134\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0769 - val_root_mean_squared_error: 0.2773\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0321 - root_mean_squared_error: 0.1791 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2412\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0213 - root_mean_squared_error: 0.1459 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0660 - val_root_mean_squared_error: 0.2568\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0535 - root_mean_squared_error: 0.2313 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2577\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0522 - val_root_mean_squared_error: 0.2285\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0409 - root_mean_squared_error: 0.2022 - val_loss: 0.0931 - val_root_mean_squared_error: 0.3052\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 33ms/step - loss: 8.0591 - root_mean_squared_error: 2.8389 - val_loss: 2.5116 - val_root_mean_squared_error: 1.5848\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0386 - root_mean_squared_error: 1.0191 - val_loss: 0.1598 - val_root_mean_squared_error: 0.3997\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3198 - root_mean_squared_error: 0.5655 - val_loss: 0.1516 - val_root_mean_squared_error: 0.3893\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1290 - root_mean_squared_error: 0.3591 - val_loss: 0.1483 - val_root_mean_squared_error: 0.3851\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0902 - root_mean_squared_error: 0.3003 - val_loss: 0.1302 - val_root_mean_squared_error: 0.3608\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0723 - root_mean_squared_error: 0.2690 - val_loss: 0.0767 - val_root_mean_squared_error: 0.2770\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0528 - root_mean_squared_error: 0.2297 - val_loss: 0.0788 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0484 - root_mean_squared_error: 0.2201 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2446\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0396 - root_mean_squared_error: 0.1990 - val_loss: 0.0620 - val_root_mean_squared_error: 0.2490\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0303 - root_mean_squared_error: 0.1741 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2528\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0274 - root_mean_squared_error: 0.1655 - val_loss: 0.0712 - val_root_mean_squared_error: 0.2669\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0256 - root_mean_squared_error: 0.1601 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2552\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0358 - root_mean_squared_error: 0.1892 - val_loss: 0.0781 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0442 - root_mean_squared_error: 0.2102 - val_loss: 0.0879 - val_root_mean_squared_error: 0.2965\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0273 - root_mean_squared_error: 0.1652 - val_loss: 0.0708 - val_root_mean_squared_error: 0.2661\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 32ms/step - loss: 7.8521 - root_mean_squared_error: 2.8022 - val_loss: 2.2581 - val_root_mean_squared_error: 1.5027\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9203 - root_mean_squared_error: 0.9593 - val_loss: 0.1480 - val_root_mean_squared_error: 0.3848\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3236 - root_mean_squared_error: 0.5688 - val_loss: 0.1357 - val_root_mean_squared_error: 0.3683\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1086 - root_mean_squared_error: 0.3295 - val_loss: 0.1093 - val_root_mean_squared_error: 0.3305\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0690 - root_mean_squared_error: 0.2626 - val_loss: 0.0615 - val_root_mean_squared_error: 0.2479\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0568 - root_mean_squared_error: 0.2383 - val_loss: 0.0739 - val_root_mean_squared_error: 0.2719\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0646 - root_mean_squared_error: 0.2541 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2515\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0382 - root_mean_squared_error: 0.1954 - val_loss: 0.0679 - val_root_mean_squared_error: 0.2607\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0284 - root_mean_squared_error: 0.1687 - val_loss: 0.0626 - val_root_mean_squared_error: 0.2501\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2433\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0260 - root_mean_squared_error: 0.1612 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2545\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - root_mean_squared_error: 0.1525 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2455\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0247 - root_mean_squared_error: 0.1573 - val_loss: 0.0696 - val_root_mean_squared_error: 0.2639\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2326\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0251 - root_mean_squared_error: 0.1585 - val_loss: 0.0868 - val_root_mean_squared_error: 0.2946\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0466 - root_mean_squared_error: 0.2158 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2313\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0261 - root_mean_squared_error: 0.1615 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2471\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0366 - root_mean_squared_error: 0.1913 - val_loss: 0.0708 - val_root_mean_squared_error: 0.2660\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0455 - root_mean_squared_error: 0.2133 - val_loss: 0.0483 - val_root_mean_squared_error: 0.2197\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0543 - root_mean_squared_error: 0.2330 - val_loss: 0.0727 - val_root_mean_squared_error: 0.2696\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0242 - root_mean_squared_error: 0.1557 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0266 - root_mean_squared_error: 0.1631 - val_loss: 0.0721 - val_root_mean_squared_error: 0.2685\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2331\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0721 - val_root_mean_squared_error: 0.2685\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.1605 - val_root_mean_squared_error: 0.4006\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 51ms/step - loss: 7.8178 - root_mean_squared_error: 2.7960 - val_loss: 2.2300 - val_root_mean_squared_error: 1.4933\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9516 - root_mean_squared_error: 0.9755 - val_loss: 0.1936 - val_root_mean_squared_error: 0.4400\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3301 - root_mean_squared_error: 0.5746 - val_loss: 0.1243 - val_root_mean_squared_error: 0.3526\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1259 - root_mean_squared_error: 0.3548 - val_loss: 0.1590 - val_root_mean_squared_error: 0.3987\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0994 - root_mean_squared_error: 0.3152 - val_loss: 0.1423 - val_root_mean_squared_error: 0.3773\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0741 - root_mean_squared_error: 0.2722 - val_loss: 0.0714 - val_root_mean_squared_error: 0.2673\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0624 - root_mean_squared_error: 0.2498 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0528 - val_root_mean_squared_error: 0.2298\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0286 - root_mean_squared_error: 0.1690 - val_loss: 0.0545 - val_root_mean_squared_error: 0.2335\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0313 - root_mean_squared_error: 0.1769 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2422\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0256 - root_mean_squared_error: 0.1601 - val_loss: 0.0602 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0250 - root_mean_squared_error: 0.1580 - val_loss: 0.0514 - val_root_mean_squared_error: 0.2268\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0306 - root_mean_squared_error: 0.1748 - val_loss: 0.0963 - val_root_mean_squared_error: 0.3103\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0568 - val_root_mean_squared_error: 0.2383\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.1262 - val_root_mean_squared_error: 0.3552\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0492 - root_mean_squared_error: 0.2219 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2503\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0246 - root_mean_squared_error: 0.1569 - val_loss: 0.0656 - val_root_mean_squared_error: 0.2562\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0368 - root_mean_squared_error: 0.1919 - val_loss: 0.0958 - val_root_mean_squared_error: 0.3096\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0422 - root_mean_squared_error: 0.2055 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2451\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 7.9656 - root_mean_squared_error: 2.8223 - val_loss: 1.8817 - val_root_mean_squared_error: 1.3717\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1809 - root_mean_squared_error: 1.0867 - val_loss: 0.1896 - val_root_mean_squared_error: 0.4354\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3352 - root_mean_squared_error: 0.5789 - val_loss: 0.1084 - val_root_mean_squared_error: 0.3292\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0909 - root_mean_squared_error: 0.3015 - val_loss: 0.0769 - val_root_mean_squared_error: 0.2773\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0732 - root_mean_squared_error: 0.2705 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2549\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0557 - root_mean_squared_error: 0.2360 - val_loss: 0.1451 - val_root_mean_squared_error: 0.3810\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0681 - root_mean_squared_error: 0.2609 - val_loss: 0.0634 - val_root_mean_squared_error: 0.2518\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0391 - root_mean_squared_error: 0.1977 - val_loss: 0.0687 - val_root_mean_squared_error: 0.2621\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0342 - root_mean_squared_error: 0.1850 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2318\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0303 - root_mean_squared_error: 0.1740 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2251\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0281 - root_mean_squared_error: 0.1678 - val_loss: 0.0453 - val_root_mean_squared_error: 0.2130\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0221 - root_mean_squared_error: 0.1487 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2097\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0243 - root_mean_squared_error: 0.1560 - val_loss: 0.0744 - val_root_mean_squared_error: 0.2728\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0319 - root_mean_squared_error: 0.1786 - val_loss: 0.0465 - val_root_mean_squared_error: 0.2157\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0312 - root_mean_squared_error: 0.1767 - val_loss: 0.0738 - val_root_mean_squared_error: 0.2717\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0516 - root_mean_squared_error: 0.2272 - val_loss: 0.0762 - val_root_mean_squared_error: 0.2761\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0357 - root_mean_squared_error: 0.1889 - val_loss: 0.0798 - val_root_mean_squared_error: 0.2825\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0663 - val_root_mean_squared_error: 0.2575\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0462 - root_mean_squared_error: 0.2149 - val_loss: 0.0679 - val_root_mean_squared_error: 0.2605\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 8.0309 - root_mean_squared_error: 2.8339 - val_loss: 1.9440 - val_root_mean_squared_error: 1.3943\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.2184 - root_mean_squared_error: 1.1038 - val_loss: 0.2398 - val_root_mean_squared_error: 0.4897\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3903 - root_mean_squared_error: 0.6247 - val_loss: 0.3287 - val_root_mean_squared_error: 0.5734\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1475 - root_mean_squared_error: 0.3841 - val_loss: 0.0904 - val_root_mean_squared_error: 0.3006\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0832 - root_mean_squared_error: 0.2885 - val_loss: 0.1004 - val_root_mean_squared_error: 0.3169\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0490 - root_mean_squared_error: 0.2213 - val_loss: 0.0634 - val_root_mean_squared_error: 0.2518\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0480 - root_mean_squared_error: 0.2190 - val_loss: 0.0634 - val_root_mean_squared_error: 0.2518\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0357 - root_mean_squared_error: 0.1890 - val_loss: 0.0685 - val_root_mean_squared_error: 0.2617\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0329 - root_mean_squared_error: 0.1813 - val_loss: 0.0662 - val_root_mean_squared_error: 0.2573\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0260 - root_mean_squared_error: 0.1614 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0261 - root_mean_squared_error: 0.1615 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2461\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0274 - root_mean_squared_error: 0.1656 - val_loss: 0.0533 - val_root_mean_squared_error: 0.2308\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0237 - root_mean_squared_error: 0.1540 - val_loss: 0.0727 - val_root_mean_squared_error: 0.2697\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0328 - root_mean_squared_error: 0.1811 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0303 - root_mean_squared_error: 0.1740 - val_loss: 0.0962 - val_root_mean_squared_error: 0.3102\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0293 - root_mean_squared_error: 0.1711 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2325\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0229 - root_mean_squared_error: 0.1513 - val_loss: 0.0677 - val_root_mean_squared_error: 0.2603\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0270 - root_mean_squared_error: 0.1643 - val_loss: 0.0800 - val_root_mean_squared_error: 0.2829\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0364 - root_mean_squared_error: 0.1907 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2222\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0395 - root_mean_squared_error: 0.1987 - val_loss: 0.0793 - val_root_mean_squared_error: 0.2815\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0475 - root_mean_squared_error: 0.2179 - val_loss: 0.0708 - val_root_mean_squared_error: 0.2660\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1387 - root_mean_squared_error: 0.3724 - val_loss: 0.2650 - val_root_mean_squared_error: 0.5148\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0679 - root_mean_squared_error: 0.2605 - val_loss: 0.0679 - val_root_mean_squared_error: 0.2606\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2408\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0356 - root_mean_squared_error: 0.1888 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2242\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0317 - root_mean_squared_error: 0.1780 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2253\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 9s 44ms/step - loss: 7.9752 - root_mean_squared_error: 2.8240 - val_loss: 1.7435 - val_root_mean_squared_error: 1.3204\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2756 - root_mean_squared_error: 1.1294 - val_loss: 0.3944 - val_root_mean_squared_error: 0.6280\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3669 - root_mean_squared_error: 0.6057 - val_loss: 0.2155 - val_root_mean_squared_error: 0.4642\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1174 - root_mean_squared_error: 0.3427 - val_loss: 0.0912 - val_root_mean_squared_error: 0.3019\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0750 - root_mean_squared_error: 0.2738 - val_loss: 0.0886 - val_root_mean_squared_error: 0.2977\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0570 - root_mean_squared_error: 0.2387 - val_loss: 0.0724 - val_root_mean_squared_error: 0.2690\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0451 - root_mean_squared_error: 0.2123 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2313\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0544 - val_root_mean_squared_error: 0.2333\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0258 - root_mean_squared_error: 0.1605 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0260 - root_mean_squared_error: 0.1613 - val_loss: 0.0516 - val_root_mean_squared_error: 0.2272\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0241 - root_mean_squared_error: 0.1553 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2266\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0244 - root_mean_squared_error: 0.1561 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0246 - root_mean_squared_error: 0.1569 - val_loss: 0.0640 - val_root_mean_squared_error: 0.2531\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0357 - root_mean_squared_error: 0.1890 - val_loss: 0.0526 - val_root_mean_squared_error: 0.2294\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0328 - root_mean_squared_error: 0.1810 - val_loss: 0.0903 - val_root_mean_squared_error: 0.3005\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0274 - root_mean_squared_error: 0.1656 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2250\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0251 - root_mean_squared_error: 0.1584 - val_loss: 0.0689 - val_root_mean_squared_error: 0.2624\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0246 - root_mean_squared_error: 0.1570 - val_loss: 0.1015 - val_root_mean_squared_error: 0.3185\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0497 - root_mean_squared_error: 0.2230 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2552\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0427 - root_mean_squared_error: 0.2067 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2509\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0317 - root_mean_squared_error: 0.1780 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2513\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0347 - root_mean_squared_error: 0.1863 - val_loss: 0.0814 - val_root_mean_squared_error: 0.2853\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0811 - val_root_mean_squared_error: 0.2848\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 43ms/step - loss: 7.8438 - root_mean_squared_error: 2.8007 - val_loss: 1.8926 - val_root_mean_squared_error: 1.3757\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0702 - root_mean_squared_error: 1.0345 - val_loss: 0.2491 - val_root_mean_squared_error: 0.4991\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2729 - root_mean_squared_error: 0.5224 - val_loss: 0.1635 - val_root_mean_squared_error: 0.4044\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0958 - root_mean_squared_error: 0.3095 - val_loss: 0.0794 - val_root_mean_squared_error: 0.2819\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0734 - root_mean_squared_error: 0.2709 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2476\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0516 - root_mean_squared_error: 0.2271 - val_loss: 0.0953 - val_root_mean_squared_error: 0.3088\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0661 - root_mean_squared_error: 0.2571 - val_loss: 0.0630 - val_root_mean_squared_error: 0.2510\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0794 - val_root_mean_squared_error: 0.2818\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0522 - root_mean_squared_error: 0.2285 - val_loss: 0.0789 - val_root_mean_squared_error: 0.2809\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0523 - val_root_mean_squared_error: 0.2288\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0285 - root_mean_squared_error: 0.1688 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2124\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0252 - root_mean_squared_error: 0.1589 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2104\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0274 - root_mean_squared_error: 0.1654 - val_loss: 0.0728 - val_root_mean_squared_error: 0.2699\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0569 - root_mean_squared_error: 0.2385 - val_loss: 0.0866 - val_root_mean_squared_error: 0.2942\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0675 - root_mean_squared_error: 0.2598 - val_loss: 0.0751 - val_root_mean_squared_error: 0.2740\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1284 - root_mean_squared_error: 0.3583 - val_loss: 0.3134 - val_root_mean_squared_error: 0.5598\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1180 - root_mean_squared_error: 0.3435 - val_loss: 0.1230 - val_root_mean_squared_error: 0.3507\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0697 - root_mean_squared_error: 0.2640 - val_loss: 0.0919 - val_root_mean_squared_error: 0.3031\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2200\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 37ms/step - loss: 7.8438 - root_mean_squared_error: 2.8007 - val_loss: 2.0958 - val_root_mean_squared_error: 1.4477\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.0702 - root_mean_squared_error: 1.0345 - val_loss: 0.2615 - val_root_mean_squared_error: 0.5114\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2729 - root_mean_squared_error: 0.5224 - val_loss: 0.1621 - val_root_mean_squared_error: 0.4027\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0958 - root_mean_squared_error: 0.3095 - val_loss: 0.1003 - val_root_mean_squared_error: 0.3167\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0734 - root_mean_squared_error: 0.2709 - val_loss: 0.0617 - val_root_mean_squared_error: 0.2485\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0516 - root_mean_squared_error: 0.2271 - val_loss: 0.0878 - val_root_mean_squared_error: 0.2964\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0661 - root_mean_squared_error: 0.2571 - val_loss: 0.0827 - val_root_mean_squared_error: 0.2876\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0712 - val_root_mean_squared_error: 0.2669\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0522 - root_mean_squared_error: 0.2285 - val_loss: 0.0722 - val_root_mean_squared_error: 0.2687\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0511 - val_root_mean_squared_error: 0.2260\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0285 - root_mean_squared_error: 0.1688 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2234\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0252 - root_mean_squared_error: 0.1589 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2234\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0274 - root_mean_squared_error: 0.1654 - val_loss: 0.0830 - val_root_mean_squared_error: 0.2881\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0569 - root_mean_squared_error: 0.2385 - val_loss: 0.1054 - val_root_mean_squared_error: 0.3246\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0675 - root_mean_squared_error: 0.2598 - val_loss: 0.0594 - val_root_mean_squared_error: 0.2436\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.1284 - root_mean_squared_error: 0.3583 - val_loss: 0.3150 - val_root_mean_squared_error: 0.5613\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1180 - root_mean_squared_error: 0.3435 - val_loss: 0.1165 - val_root_mean_squared_error: 0.3413\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0697 - root_mean_squared_error: 0.2640 - val_loss: 0.0723 - val_root_mean_squared_error: 0.2689\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2228\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2331\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0228 - root_mean_squared_error: 0.1511 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2549\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0240 - root_mean_squared_error: 0.1548 - val_loss: 0.0688 - val_root_mean_squared_error: 0.2623\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0241 - root_mean_squared_error: 0.1552 - val_loss: 0.0675 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0282 - root_mean_squared_error: 0.1678 - val_loss: 0.0558 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0219 - root_mean_squared_error: 0.1480 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2318\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 35ms/step - loss: 6.5084 - root_mean_squared_error: 2.5512 - val_loss: 2.0276 - val_root_mean_squared_error: 1.4239\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.8311 - root_mean_squared_error: 0.9117 - val_loss: 0.1413 - val_root_mean_squared_error: 0.3759\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.2403 - root_mean_squared_error: 0.4902 - val_loss: 0.1345 - val_root_mean_squared_error: 0.3668\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1035 - root_mean_squared_error: 0.3217 - val_loss: 0.0808 - val_root_mean_squared_error: 0.2842\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0757 - root_mean_squared_error: 0.2752 - val_loss: 0.0737 - val_root_mean_squared_error: 0.2715\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0564 - root_mean_squared_error: 0.2376 - val_loss: 0.0777 - val_root_mean_squared_error: 0.2788\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0430 - root_mean_squared_error: 0.2074 - val_loss: 0.0703 - val_root_mean_squared_error: 0.2651\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0477 - root_mean_squared_error: 0.2183 - val_loss: 0.0662 - val_root_mean_squared_error: 0.2573\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0618 - root_mean_squared_error: 0.2485 - val_loss: 0.0952 - val_root_mean_squared_error: 0.3086\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0591 - root_mean_squared_error: 0.2430 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0465 - root_mean_squared_error: 0.2156 - val_loss: 0.0495 - val_root_mean_squared_error: 0.2225\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0612 - val_root_mean_squared_error: 0.2474\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0303 - root_mean_squared_error: 0.1740 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2214\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0270 - root_mean_squared_error: 0.1645 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2397\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0259 - root_mean_squared_error: 0.1609 - val_loss: 0.0823 - val_root_mean_squared_error: 0.2870\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0352 - root_mean_squared_error: 0.1877 - val_loss: 0.0721 - val_root_mean_squared_error: 0.2685\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0408 - root_mean_squared_error: 0.2019 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2596\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0726 - val_root_mean_squared_error: 0.2694\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0288 - root_mean_squared_error: 0.1698 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2159\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671 - val_loss: 0.0683 - val_root_mean_squared_error: 0.2613\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 35ms/step - loss: 6.6662 - root_mean_squared_error: 2.5819 - val_loss: 2.6448 - val_root_mean_squared_error: 1.6263\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8474 - root_mean_squared_error: 0.9205 - val_loss: 0.4776 - val_root_mean_squared_error: 0.6911\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2861 - root_mean_squared_error: 0.5349 - val_loss: 0.1986 - val_root_mean_squared_error: 0.4456\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1056 - root_mean_squared_error: 0.3249 - val_loss: 0.0749 - val_root_mean_squared_error: 0.2736\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0564 - root_mean_squared_error: 0.2375 - val_loss: 0.0656 - val_root_mean_squared_error: 0.2561\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0350 - root_mean_squared_error: 0.1872 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0621 - val_root_mean_squared_error: 0.2491\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0680 - val_root_mean_squared_error: 0.2608\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0304 - root_mean_squared_error: 0.1745 - val_loss: 0.0570 - val_root_mean_squared_error: 0.2386\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2486\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0522 - val_root_mean_squared_error: 0.2285\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0309 - root_mean_squared_error: 0.1757 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2467\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0249 - root_mean_squared_error: 0.1579 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0217 - root_mean_squared_error: 0.1472 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2280\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0245 - root_mean_squared_error: 0.1566 - val_loss: 0.0644 - val_root_mean_squared_error: 0.2538\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0258 - root_mean_squared_error: 0.1605 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2487\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0220 - root_mean_squared_error: 0.1485 - val_loss: 0.0646 - val_root_mean_squared_error: 0.2541\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.1022 - val_root_mean_squared_error: 0.3196\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0356 - root_mean_squared_error: 0.1887 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2326\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0223 - root_mean_squared_error: 0.1493 - val_loss: 0.0655 - val_root_mean_squared_error: 0.2559\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0212 - root_mean_squared_error: 0.1454 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2471\n"
     ]
    }
   ],
   "source": [
    "# empty dict to store results\n",
    "evals_by_year = {}\n",
    "\n",
    "results_by_year={}\n",
    "\n",
    "drop_yrs = [1982, 1999, 2005, 2006]\n",
    "years = list(range(1980,2024))\n",
    "yrs = [y for y in years if y not in drop_yrs]\n",
    "\n",
    "for year in yrs:\n",
    "    df_test = df[df['Year'] == year] # create test dataframe of one year\n",
    "    years1 = list(range(1980,2024))\n",
    "    yrs1 = [y for y in years1 if y not in drop_yrs]\n",
    "    yrs1.remove(year) # remove test year from list\n",
    "    random.seed(10)\n",
    "    valid_years = random.sample(yrs1, 3) # generate 3 random years for validation data\n",
    "    df_valid = df[df['Year'].isin(valid_years)] # create validation dataframe\n",
    "    df_train = df[~df['Year'].isin([year] + list(valid_years))] # training dataframe with remaining years\n",
    "    X_test =  df_test[cols]\n",
    "    y_test = df_test['Share']\n",
    "    X_valid =  df_valid[cols]\n",
    "    y_valid = df_valid['Share']\n",
    "    X_train = df_train[cols]\n",
    "    y_train = df_train['Share']\n",
    "    tf.random.set_seed(42)\n",
    "    norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "    #initializer = tf.keras.initializers.LecunNormal(seed=42)\n",
    "    model = tf.keras.Sequential([\n",
    "        norm_layer,\n",
    "        tf.keras.layers.Dense(74, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "        tf.keras.layers.Dense(74, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "    norm_layer.adapt(X_train)\n",
    "    history = model.fit(X_train, y_train, epochs=30,\n",
    "                        validation_data=(X_valid,y_valid),\n",
    "                        callbacks=callbacks\n",
    "                        )\n",
    "    pred = model(X_test)                       \n",
    "    eval, results = evaluate(y_test, pred)\n",
    "    evals_by_year[year] = eval\n",
    "    results_by_year[year] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MVP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-0.071500</td>\n",
       "      <td>0.087041</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>-0.808806</td>\n",
       "      <td>0.152358</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.645508</td>\n",
       "      <td>0.026283</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.074076</td>\n",
       "      <td>0.067651</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.409492</td>\n",
       "      <td>0.056678</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.640889</td>\n",
       "      <td>0.033042</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.736587</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.500095</td>\n",
       "      <td>0.044347</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.084124</td>\n",
       "      <td>0.077104</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-0.016989</td>\n",
       "      <td>0.084984</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.274434</td>\n",
       "      <td>0.066048</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.501949</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.761339</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>0.728413</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>Wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>-0.234572</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.662693</td>\n",
       "      <td>0.017355</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.118594</td>\n",
       "      <td>0.054671</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.831891</td>\n",
       "      <td>0.011420</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.686999</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.699747</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.607015</td>\n",
       "      <td>0.032547</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.172007</td>\n",
       "      <td>0.066859</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.166424</td>\n",
       "      <td>0.062571</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.523209</td>\n",
       "      <td>0.039137</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.431036</td>\n",
       "      <td>0.053728</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.836218</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.645851</td>\n",
       "      <td>0.033092</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.312383</td>\n",
       "      <td>0.066458</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.295371</td>\n",
       "      <td>0.070759</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.468592</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.742669</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.701405</td>\n",
       "      <td>0.029106</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.584286</td>\n",
       "      <td>0.043047</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.676654</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.424862</td>\n",
       "      <td>0.054574</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.324325</td>\n",
       "      <td>0.068696</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.689354</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.752026</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.637917</td>\n",
       "      <td>0.036169</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.728532</td>\n",
       "      <td>0.026033</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2       MSE      MVP\n",
       "Idx                              \n",
       "1983 -0.071500  0.087041    Wrong\n",
       "1987 -0.808806  0.152358    Wrong\n",
       "1989  0.645508  0.026283    Wrong\n",
       "1990  0.074076  0.067651    Wrong\n",
       "1993  0.409492  0.056678    Wrong\n",
       "1994  0.640889  0.033042    Wrong\n",
       "1998  0.736587  0.026564    Wrong\n",
       "2001  0.500095  0.044347    Wrong\n",
       "2002  0.084124  0.077104    Wrong\n",
       "2003 -0.016989  0.084984    Wrong\n",
       "2011  0.274434  0.066048    Wrong\n",
       "2012  0.501949  0.045995    Wrong\n",
       "2022  0.761339  0.024178    Wrong\n",
       "2023  0.728413  0.028981    Wrong\n",
       "1980 -0.234572  0.049887  Correct\n",
       "1981  0.662693  0.017355  Correct\n",
       "1984  0.118594  0.054671  Correct\n",
       "1985  0.831891  0.011420  Correct\n",
       "1986  0.686999  0.025079  Correct\n",
       "1988  0.699747  0.027045  Correct\n",
       "1991  0.607015  0.032547  Correct\n",
       "1992  0.172007  0.066859  Correct\n",
       "1995  0.166424  0.062571  Correct\n",
       "1996  0.523209  0.039137  Correct\n",
       "1997  0.431036  0.053728  Correct\n",
       "2000  0.836218  0.011443  Correct\n",
       "2004  0.645851  0.033092  Correct\n",
       "2007  0.312383  0.066458  Correct\n",
       "2008  0.295371  0.070759  Correct\n",
       "2009  0.468592  0.053838  Correct\n",
       "2010  0.742669  0.024684  Correct\n",
       "2013  0.701405  0.029106  Correct\n",
       "2014  0.584286  0.043047  Correct\n",
       "2015  0.676654  0.031703  Correct\n",
       "2016  0.424862  0.054574  Correct\n",
       "2017  0.324325  0.068696  Correct\n",
       "2018  0.689354  0.031966  Correct\n",
       "2019  0.752026  0.024532  Correct\n",
       "2020  0.637917  0.036169  Correct\n",
       "2021  0.728532  0.026033  Correct"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn4_res = pd.DataFrame(list(evals_by_year.values()), index=evals_by_year.keys())\n",
    "nn4_res.columns = ['R2', 'MSE', 'MVP']\n",
    "nn4_res.index.name='Idx'\n",
    "nn4_res.sort_values(by = ['MVP', 'Idx'], ascending = [False, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Correct    26\n",
       "Wrong      14\n",
       "Name: MVP, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn4_res['MVP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2     0.448627\n",
       "MSE    0.046691\n",
       "dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn4_res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Share</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Joel Embiid</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.495415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nikola Jokić</th>\n",
       "      <td>0.674</td>\n",
       "      <td>0.730018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giannis Antetokounmpo</th>\n",
       "      <td>0.606</td>\n",
       "      <td>0.610472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jayson Tatum</th>\n",
       "      <td>0.280</td>\n",
       "      <td>0.263288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai Gilgeous-Alexander</th>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.049087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donovan Mitchell</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.041728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domantas Sabonis</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.035072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luka Dončić</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.302613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephen Curry</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.128049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jimmy Butler</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.014670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Share  prediction\n",
       "Player                                    \n",
       "Joel Embiid              0.915    0.495415\n",
       "Nikola Jokić             0.674    0.730018\n",
       "Giannis Antetokounmpo    0.606    0.610472\n",
       "Jayson Tatum             0.280    0.263288\n",
       "Shai Gilgeous-Alexander  0.046   -0.049087\n",
       "Donovan Mitchell         0.030    0.041728\n",
       "Domantas Sabonis         0.027    0.035072\n",
       "Luka Dončić              0.010    0.302613\n",
       "Stephen Curry            0.005    0.128049\n",
       "Jimmy Butler             0.003   -0.014670"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_by_year[2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber and Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1980</th>\n",
       "      <th>0</th>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1981</th>\n",
       "      <th>9</th>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1982</th>\n",
       "      <th>45</th>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1983</th>\n",
       "      <th>70</th>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>48.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1984</th>\n",
       "      <th>99</th>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>49.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>40.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1985</th>\n",
       "      <th>116</th>\n",
       "      <td>97.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>27.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1986</th>\n",
       "      <th>139</th>\n",
       "      <td>98.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1987</th>\n",
       "      <th>157</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1988</th>\n",
       "      <th>174</th>\n",
       "      <td>83.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1989</th>\n",
       "      <th>191</th>\n",
       "      <td>78.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1990</th>\n",
       "      <th>210</th>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>61.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1991</th>\n",
       "      <th>224</th>\n",
       "      <td>92.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1992</th>\n",
       "      <th>244</th>\n",
       "      <td>93.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1993</th>\n",
       "      <th>261</th>\n",
       "      <td>85.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>57.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1994</th>\n",
       "      <th>275</th>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>72.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1995</th>\n",
       "      <th>293</th>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1996</th>\n",
       "      <th>309</th>\n",
       "      <td>98.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>50.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1997</th>\n",
       "      <th>326</th>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>83.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1998</th>\n",
       "      <th>346</th>\n",
       "      <td>93.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>72.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1999</th>\n",
       "      <th>365</th>\n",
       "      <td>70.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2000</th>\n",
       "      <th>386</th>\n",
       "      <td>99.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2001</th>\n",
       "      <th>402</th>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2002</th>\n",
       "      <th>419</th>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>55.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2003</th>\n",
       "      <th>437</th>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>41.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2004</th>\n",
       "      <th>450</th>\n",
       "      <td>99.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2005</th>\n",
       "      <th>466</th>\n",
       "      <td>83.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>81.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2006</th>\n",
       "      <th>483</th>\n",
       "      <td>73.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2007</th>\n",
       "      <th>494</th>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>78.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>40.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2008</th>\n",
       "      <th>511</th>\n",
       "      <td>87.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>53.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2009</th>\n",
       "      <th>528</th>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>57.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>56.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2010</th>\n",
       "      <th>541</th>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>48.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2011</th>\n",
       "      <th>557</th>\n",
       "      <td>97.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2012</th>\n",
       "      <th>570</th>\n",
       "      <td>88.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>31.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>585</th>\n",
       "      <td>99.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>39.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2014</th>\n",
       "      <th>601</th>\n",
       "      <td>98.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2015</th>\n",
       "      <th>618</th>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016</th>\n",
       "      <th>630</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>48.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017</th>\n",
       "      <th>640</th>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018</th>\n",
       "      <th>651</th>\n",
       "      <td>95.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>73.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>44.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019</th>\n",
       "      <th>664</th>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>76.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2020</th>\n",
       "      <th>676</th>\n",
       "      <td>95.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>36.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2021</th>\n",
       "      <th>688</th>\n",
       "      <td>96.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2022</th>\n",
       "      <th>705</th>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>70.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>59.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2023</th>\n",
       "      <th>717</th>\n",
       "      <td>91.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>67.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Share\n",
       "Year           \n",
       "1980 0     66.5\n",
       "     1     14.3\n",
       "     2      8.6\n",
       "1981 9     65.8\n",
       "     10    61.3\n",
       "     11    41.4\n",
       "1982 45    73.5\n",
       "     46    58.8\n",
       "     47    29.4\n",
       "1983 70    96.0\n",
       "     71    48.5\n",
       "     72    40.6\n",
       "1984 99    85.8\n",
       "     100   49.1\n",
       "     101   40.1\n",
       "1985 116   97.8\n",
       "     117   33.8\n",
       "     118   27.9\n",
       "1986 139   98.1\n",
       "     140   52.2\n",
       "     141   26.3\n",
       "1987 157   94.0\n",
       "     158   57.6\n",
       "     159   34.7\n",
       "1988 174   83.1\n",
       "     175   65.9\n",
       "     176   63.5\n",
       "1989 191   78.2\n",
       "     192   70.4\n",
       "     193   42.6\n",
       "1990 210   69.1\n",
       "     211   66.7\n",
       "     212   61.3\n",
       "1991 224   92.8\n",
       "     225   51.8\n",
       "     226   49.6\n",
       "1992 244   93.8\n",
       "     245   58.4\n",
       "     246   35.1\n",
       "1993 261   85.2\n",
       "     262   66.0\n",
       "     263   57.7\n",
       "1994 275   88.0\n",
       "     276   72.3\n",
       "     277   38.6\n",
       "1995 293   85.8\n",
       "     294   57.6\n",
       "     295   50.7\n",
       "1996 309   98.6\n",
       "     310   50.8\n",
       "     311   31.9\n",
       "1997 326   85.7\n",
       "     327   83.2\n",
       "     328   32.7\n",
       "1998 346   93.4\n",
       "     347   72.6\n",
       "     348   37.2\n",
       "1999 365   70.1\n",
       "     366   65.5\n",
       "     367   62.7\n",
       "2000 386   99.8\n",
       "     387   33.7\n",
       "     388   30.3\n",
       "2001 402   90.4\n",
       "     403   56.9\n",
       "     404   46.6\n",
       "2002 419   75.7\n",
       "     420   71.2\n",
       "     421   55.2\n",
       "2003 437   80.8\n",
       "     438   73.2\n",
       "     439   41.7\n",
       "2004 450   99.1\n",
       "     451   58.2\n",
       "     452   42.5\n",
       "2005 466   83.9\n",
       "     467   81.3\n",
       "     468   27.5\n",
       "2006 483   73.9\n",
       "     484   55.0\n",
       "     485   43.5\n",
       "2007 494   88.2\n",
       "     495   78.5\n",
       "     496   40.4\n",
       "2008 511   87.3\n",
       "     512   71.0\n",
       "     513   53.2\n",
       "2009 528   96.9\n",
       "     529   57.7\n",
       "     530   56.2\n",
       "2010 541   98.0\n",
       "     542   49.5\n",
       "     543   48.7\n",
       "2011 557   97.7\n",
       "     558   53.1\n",
       "     559   43.1\n",
       "2012 570   88.8\n",
       "     571   73.5\n",
       "     572   31.8\n",
       "2013 585   99.8\n",
       "     586   63.2\n",
       "     587   39.3\n",
       "2014 601   98.6\n",
       "     602   71.3\n",
       "     603   34.7\n",
       "2015 618   92.2\n",
       "     619   72.0\n",
       "     620   42.5\n",
       "2016 630  100.0\n",
       "     631   48.4\n",
       "     632   48.2\n",
       "2017 640   87.9\n",
       "     641   74.6\n",
       "     642   49.5\n",
       "2018 651   95.5\n",
       "     652   73.1\n",
       "     653   44.1\n",
       "2019 664   93.2\n",
       "     665   76.8\n",
       "     666   35.2\n",
       "2020 676   95.2\n",
       "     677   74.6\n",
       "     678   36.3\n",
       "2021 688   96.1\n",
       "     689   58.0\n",
       "     690   44.9\n",
       "2022 705   87.5\n",
       "     706   70.6\n",
       "     707   59.5\n",
       "2023 717   91.5\n",
       "     718   67.4\n",
       "     719   60.6"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.DataFrame(df.groupby(['Year'])['Share'].nlargest(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_huber(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_large_y = y_true > 35\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error)\n",
    "    return tf.where(is_large_y, squared_loss, linear_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save at the end, move to the end\n",
    "model.save(\"my_keras_model\", save_format=\"tf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0dec2d63b7814454e75af1cdd1da16dfbf6538085e18c478c68b217dc309d1fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
